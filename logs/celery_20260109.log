[WARNING] 2026-01-09 14:08:49.089 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:08:49.233 Connected to redis://default:**@10.0.62.214:6379/0
[WARNING] 2026-01-09 14:08:49.236 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:08:49.375 mingle: searching for neighbors
[INFO] 2026-01-09 14:08:51.043 mingle: sync with 1 nodes
[INFO] 2026-01-09 14:08:51.044 mingle: sync complete
[INFO] 2026-01-09 14:08:51.882 celery@DESKTOP-4FIVBBU ready.
[WARNING] 2026-01-09 14:12:52.161 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:12:54.223 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 14:12:54.225 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:12:56.297 mingle: searching for neighbors
[INFO] 2026-01-09 14:13:03.492 mingle: all alone
[INFO] 2026-01-09 14:13:13.800 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 14:13:39.492 Task celery_app.tasks.generate_slides_task[ab0252f9-2ac2-459f-85bc-abdeb3b020b2] received
[INFO] 2026-01-09 14:13:41.663 开始执行任务: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, update_system=True
[INFO] 2026-01-09 14:13:41.663 开始执行任务: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, update_system=True
[INFO] 2026-01-09 14:13:45.115 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 14:13:45.194 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始参数校验...
[INFO] 2026-01-09 14:13:45.194 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始参数校验...
[INFO] 2026-01-09 14:13:45.207 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 任务状态已更新为 running
[INFO] 2026-01-09 14:13:45.207 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 任务状态已更新为 running
[INFO] 2026-01-09 14:13:45.226 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始下载文件...
[INFO] 2026-01-09 14:13:45.226 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始下载文件...
[INFO] 2026-01-09 14:13:45.227 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:13:45.227 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:13:45.228 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 14:13:45.229 MinIO客户端初始化成功
[INFO] 2026-01-09 14:13:45.493 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\2501.11921.md
[INFO] 2026-01-09 14:13:45.495 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\2501.11921.md
[INFO] 2026-01-09 14:13:45.495 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\2501.11921.md
[INFO] 2026-01-09 14:13:45.499 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始调用生成管道...
[INFO] 2026-01-09 14:13:45.499 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始调用生成管道...
[INFO] 2026-01-09 14:13:45.503 Starting pipeline from stage: rag
[INFO] 2026-01-09 14:13:45.504 Session ID: dbb538b5-22b8-46ad-b6e4-93b91f2548c1
[INFO] 2026-01-09 14:13:45.505 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 14:13:45.506 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 14:13:45.513 
[INFO] 2026-01-09 14:13:45.514 Starting from stage: rag
[INFO] 2026-01-09 14:13:45.514 
[INFO] 2026-01-09 14:13:45.515 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:45.516 STAGE: RAG
[INFO] 2026-01-09 14:13:45.516 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:45.519 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 14:13:48.262 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 14:13:48.264 Found 7 external images to download
[INFO] 2026-01-09 14:13:48.476 Successfully downloaded 7 images
[INFO] 2026-01-09 14:13:48.478   Built content_list with 15 items
[INFO] 2026-01-09 14:13:48.478   Found 1 markdown file(s)
[INFO] 2026-01-09 14:13:48.479 
[INFO] 2026-01-09 14:13:48.479 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 14:13:50.640 Processing markdown files and embedding images...
[WARNING] 2026-01-09 14:13:50.642 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\8c0fbe7b8b7042b32e81652b092d18ba9592e23ac68dc3e47f650184f1aa6e52.png
[WARNING] 2026-01-09 14:13:50.644 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\3500959562fb2cb6e18c85ecd8caf910d95700bd7b619e6a5a310c3f1f0ba8cc.png
[WARNING] 2026-01-09 14:13:50.646 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\e34839d172aafb33e51cfd2474d13cb5f116c7a0390e4c3056705fa04fa80983.png
[WARNING] 2026-01-09 14:13:50.647 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\8e52fa30ffc5b4ba0465de558256e2a2a07ca6c920246abdc7fd7f9149d50cac.png
[WARNING] 2026-01-09 14:13:50.647 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\6a5c96c530308e7bf39691c193587b2f7f50a44610d8ddfa315afd574e7e54a5.png
[WARNING] 2026-01-09 14:13:50.648 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\8a4b87e4631c1ad6fe4060f5eb60fc992fd8743289d4b0e794598f05965f4711.png
[WARNING] 2026-01-09 14:13:50.649 Image not found: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\ab0252f9-2ac2-459f-85bc-abdeb3b020b2\http:\61.160.97.222:59003\kb-paper-images\arxiv-2025-2501.11921\54abcbaad4d7406bc6856bb758310fa92aaa124203532d704e2bafdc65f450dd.png
[INFO] 2026-01-09 14:13:50.660   2501.11921.md: embedded 0 images
[INFO] 2026-01-09 14:13:50.662 Total embedded images: 0
[ERROR] 2026-01-09 14:13:52.292 Query failed: List the paper title, author names and their insti... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.293 Query failed: What is the core model formulation or main equatio... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.296 Query failed: Show the main performance comparison table with al... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.297 Query failed: What method, approach, or framework does this pape... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.299 Query failed: Describe the architecture or framework diagram. Wh... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.347 Query failed: Show the ablation study table with all variants an... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.460 Query failed: Show any dataset statistics table with sizes, spli... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.516 Query failed: What problem or task does this paper aim to solve?... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.565 Query failed: What are the limitations or drawbacks of existing ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.590 Query failed: What gap or unmet need motivates this research? Ho... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.756 Query failed: What are the main components, modules, or steps of... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.800 Query failed: Describe the system design, model structure, or th... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.802 Query failed: What are the key parameters, settings, or implemen... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.803 Query failed: What is the algorithm, procedure, or workflow? Des... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.897 Query failed: What are the key equations, formulas, or mathemati... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.910 Query failed: What datasets, benchmarks, or experimental setups ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.936 Query failed: How does the proposed method compare to baseline m... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.943 Query failed: What objective function, optimization goal, or the... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.945 Query failed: What are the main results shown in the main result... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.946 Query failed: What evaluation metrics or criteria are used to me... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:52.995 Query failed: What performance does the method achieve? Report t... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:53.124 Query failed: What analysis, case study, or discussion of the re... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:53.127 Query failed: What ablation study or sensitivity analysis is con... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:53.157 Query failed: What is novel or new about this work compared to e... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:53.167 Query failed: What are the main contributions listed in the intr... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 14:13:53.229 Query failed: What limitations does the paper acknowledge? What ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[INFO] 2026-01-09 14:13:53.231   Completed 26 queries
[INFO] 2026-01-09 14:13:53.243   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 14:13:53.246 
[INFO] 2026-01-09 14:13:53.247 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:53.248 STAGE: SUMMARY
[INFO] 2026-01-09 14:13:53.248 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:55.169 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 14:13:55.170   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 14:13:58.927   Paper metadata extracted successfully
[INFO] 2026-01-09 14:13:58.929   Summary: 186 chars
[INFO] 2026-01-09 14:13:58.930 Extracting tables and figures...
[INFO] 2026-01-09 14:13:58.935   Tables: 2, Figures: 0
[INFO] 2026-01-09 14:13:58.955   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 14:13:58.957 
[INFO] 2026-01-09 14:13:58.957 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:58.958 STAGE: PLAN
[INFO] 2026-01-09 14:13:58.958 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:13:58.978 Planning content...
[INFO] 2026-01-09 14:14:00.800 Calling LLM with text only (no images)
[INFO] 2026-01-09 14:14:00.800 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 14:14:14.512 LLM returned 6095 characters
[INFO] 2026-01-09 14:14:14.513 ================================================================================
[INFO] 2026-01-09 14:14:14.514 LLM Response for Content Planning:
[INFO] 2026-01-09 14:14:14.514 --------------------------------------------------------------------------------
[INFO] 2026-01-09 14:14:14.514 ```json
{
  "sections": [
    {
      "id": "poster_header",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Authors: Jiazheng Chen, Wanchun Liu*. This research addresses the critical challenge of scheduling in goal-oriented communications where the Age of Information (AoI) and energy efficiency must be balanced across multiple users. The paper introduces SUDO-DRL, a novel framework designed to handle large-scale system states while maintaining high performance through structural guidance and a hybrid learning strategy.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_background",
      "title": "Background and Motivation",
      "content": "In goal-oriented communication systems, the objective is to minimize a specific cost function, often related to the freshness of information (AoI) and resource consumption. Traditional Deep Reinforcement Learning (DRL) methods like PPO or DDPG face significant scaling issues as the number of users $N$ and channels $M$ increases. Existing approaches often suffer from high sample complexity and instability in high-dimensional action spaces. The primary motivation is to exploit the underlying mathematical structure of the optimal scheduling policy—specifically its monotonicity with respect to AoI—to guide the learning process. By integrating this structural knowledge into a DRL framework, the agent can avoid exploring sub-optimal regions of the state-action space, leading to faster convergence and better scalability in complex network environments.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "Methodology: The SUDO-DRL Framework",
      "content": "The SUDO-DRL framework consists of two main technical innovations: Structure-guided learning and a Unified Dual On-policy/Off-policy (SUDO) update mechanism. \n1. **Structure-guided Exploration**: The po
[INFO] 2026-01-09 14:14:14.515 ... (truncated, total length: 6095 chars)
[INFO] 2026-01-09 14:14:14.515 ================================================================================
[INFO] 2026-01-09 14:14:14.520 Found JSON in code block
[INFO] 2026-01-09 14:14:14.525   Generated 5 sections:
[INFO] 2026-01-09 14:14:14.526     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 14:14:14.527     [2] Background and Motivation (content)
[INFO] 2026-01-09 14:14:14.527     [3] Methodology: The SUDO-DRL Framework (content)
[INFO] 2026-01-09 14:14:14.528     [4] Experimental Results and Performance Analysis (content)
[INFO] 2026-01-09 14:14:14.529     [5] Conclusion and Contributions (content)
[INFO] 2026-01-09 14:14:14.536   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 14:14:14.540 
[INFO] 2026-01-09 14:14:14.542 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:14:14.543 STAGE: GENERATE
[INFO] 2026-01-09 14:14:14.543 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:14:14.561 Generating images...
[INFO] 2026-01-09 14:14:16.697 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 14:14:16.699   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 14:14:16.699   Prompt length: 5596 chars
[INFO] 2026-01-09 14:15:14.539 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 14:15:15.193 Image generation successful (Doubao, URL, 1332872 bytes)
[INFO] 2026-01-09 14:15:15.196   [1/1] Saved: poster.png
[INFO] 2026-01-09 14:15:15.197   Generated 1 images
[INFO] 2026-01-09 14:15:15.197 
[INFO] 2026-01-09 14:15:15.198 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_141414
[INFO] 2026-01-09 14:15:15.200 
[INFO] 2026-01-09 14:15:15.200 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:15:15.201 SUMMARY
[INFO] 2026-01-09 14:15:15.201 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:15:15.202   [✓] rag: completed
[INFO] 2026-01-09 14:15:15.202   [✓] summary: completed
[INFO] 2026-01-09 14:15:15.202   [✓] plan: completed
[INFO] 2026-01-09 14:15:15.203   [✓] generate: completed
[INFO] 2026-01-09 14:15:15.204 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 14:15:15.204 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 14:15:15.208 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始上传文件...
[INFO] 2026-01-09 14:15:15.208 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始上传文件...
[INFO] 2026-01-09 14:15:15.537 文件已上传: kb-poster-system/arxiv/2501.11921/poster.png
[INFO] 2026-01-09 14:15:15.539 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 文件上传完成: kb-poster-system/arxiv/2501.11921/poster.png
[INFO] 2026-01-09 14:15:15.539 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 文件上传完成: kb-poster-system/arxiv/2501.11921/poster.png
[INFO] 2026-01-09 14:15:15.551 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始更新用户数据...
[INFO] 2026-01-09 14:15:15.551 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始更新用户数据...
[INFO] 2026-01-09 14:15:15.570 批量更新完成: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, update_system=True
[INFO] 2026-01-09 14:15:15.570 批量更新完成: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, update_system=True
[INFO] 2026-01-09 14:15:15.572 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 用户数据更新完成
[INFO] 2026-01-09 14:15:15.572 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 用户数据更新完成
[INFO] 2026-01-09 14:15:15.575 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始更新系统数据...
[INFO] 2026-01-09 14:15:15.575 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 开始更新系统数据...
[INFO] 2026-01-09 14:15:15.579 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 系统数据更新完成, update_system=True
[INFO] 2026-01-09 14:15:15.579 [ab0252f9-2ac2-459f-85bc-abdeb3b020b2] 系统数据更新完成, update_system=True
[INFO] 2026-01-09 14:15:15.586 任务执行完成: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, status=success
[INFO] 2026-01-09 14:15:15.586 任务执行完成: ab0252f9-2ac2-459f-85bc-abdeb3b020b2, status=success
[INFO] 2026-01-09 14:15:15.587 任务成功: ab0252f9-2ac2-459f-85bc-abdeb3b020b2
[INFO] 2026-01-09 14:15:15.587 任务成功: ab0252f9-2ac2-459f-85bc-abdeb3b020b2
[INFO] 2026-01-09 14:15:17.650 运行中任务数减少: 0
[INFO] 2026-01-09 14:15:17.654 已清理临时文件: ab0252f9-2ac2-459f-85bc-abdeb3b020b2
[INFO] 2026-01-09 14:15:17.654 已清理临时文件: ab0252f9-2ac2-459f-85bc-abdeb3b020b2
[INFO] 2026-01-09 14:15:17.660 Task celery_app.tasks.generate_slides_task[ab0252f9-2ac2-459f-85bc-abdeb3b020b2] succeeded in 98.15599999995902s: {'result_id': 'ab0252f9-2ac2-459f-85bc-abdeb3b020b2', 'status': 'success', 'file_path': 'kb-poster-system/arxiv/2501.11921/poster.png', 'images': None, 'error_message': None}
[INFO] 2026-01-09 14:24:31.265 Task celery_app.tasks.generate_slides_task[56039e63-de7c-4909-aac9-dadaa9a37ac4] received
[INFO] 2026-01-09 14:24:31.269 开始执行任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 14:24:31.269 开始执行任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 14:24:31.348 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始参数校验...
[INFO] 2026-01-09 14:24:31.348 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始参数校验...
[INFO] 2026-01-09 14:24:31.355 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 任务状态已更新为 running
[INFO] 2026-01-09 14:24:31.355 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 任务状态已更新为 running
[INFO] 2026-01-09 14:24:31.363 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始下载文件...
[INFO] 2026-01-09 14:24:31.363 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始下载文件...
[INFO] 2026-01-09 14:24:31.366 [56039e63-de7c-4909-aac9-dadaa9a37ac4] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:24:31.366 [56039e63-de7c-4909-aac9-dadaa9a37ac4] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:24:31.551 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 14:24:31.551 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 14:24:31.551 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 14:24:31.556 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始调用生成管道...
[INFO] 2026-01-09 14:24:31.556 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始调用生成管道...
[INFO] 2026-01-09 14:24:31.559 Starting pipeline from stage: rag
[INFO] 2026-01-09 14:24:31.559 Session ID: 66a5c59a-e7ee-4933-b68b-2bc91851fa71
[INFO] 2026-01-09 14:24:31.559 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 14:24:31.560 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 14:24:31.566 
[INFO] 2026-01-09 14:24:31.567 Starting from stage: rag
[INFO] 2026-01-09 14:24:31.567 
[INFO] 2026-01-09 14:24:31.567 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:24:31.569 STAGE: RAG
[INFO] 2026-01-09 14:24:31.569 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:24:31.572 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 14:24:31.572 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 14:24:31.574 Found 7 external images to download
[INFO] 2026-01-09 14:24:31.777 Successfully downloaded 7 images
[INFO] 2026-01-09 14:26:37.366   Built content_list with 15 items
[INFO] 2026-01-09 14:26:37.366   Found 1 markdown file(s)
[INFO] 2026-01-09 14:26:37.367 
[INFO] 2026-01-09 14:26:37.367 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 14:26:38.724 Processing markdown files and embedding images...
[WARNING] 2026-01-09 14:33:00.900 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:33:02.923 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 14:33:02.924 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:33:07.028 mingle: searching for neighbors
[INFO] 2026-01-09 14:33:14.191 mingle: all alone
[INFO] 2026-01-09 14:33:22.361 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 14:33:34.589 Task celery_app.tasks.generate_slides_task[b9bd2879-d3da-48e2-811e-8e30cb41668f] received
[INFO] 2026-01-09 14:33:36.670 开始执行任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 14:33:36.670 开始执行任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 14:33:39.988 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 14:33:40.066 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始参数校验...
[INFO] 2026-01-09 14:33:40.066 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始参数校验...
[INFO] 2026-01-09 14:33:40.074 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 任务状态已更新为 running
[INFO] 2026-01-09 14:33:40.074 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 任务状态已更新为 running
[INFO] 2026-01-09 14:33:40.086 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始下载文件...
[INFO] 2026-01-09 14:33:40.086 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始下载文件...
[INFO] 2026-01-09 14:33:40.088 [b9bd2879-d3da-48e2-811e-8e30cb41668f] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:33:40.088 [b9bd2879-d3da-48e2-811e-8e30cb41668f] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:33:40.089 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 14:33:40.091 MinIO客户端初始化成功
[INFO] 2026-01-09 14:33:40.392 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 14:33:40.395 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 14:33:40.395 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 14:33:40.404 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始调用生成管道...
[INFO] 2026-01-09 14:33:40.404 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始调用生成管道...
[INFO] 2026-01-09 14:33:40.407 Starting pipeline from stage: rag
[INFO] 2026-01-09 14:33:40.407 Session ID: 6d76cfef-417b-42cb-af63-c7eb594cd0b3
[INFO] 2026-01-09 14:33:40.408 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 14:33:40.408 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 14:33:40.419 
[INFO] 2026-01-09 14:33:40.419 Starting from stage: rag
[INFO] 2026-01-09 14:33:40.420 
[INFO] 2026-01-09 14:33:40.420 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:33:40.420 STAGE: RAG
[INFO] 2026-01-09 14:33:40.422 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:33:40.423 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 14:33:43.258 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 14:33:43.261 Found 7 external images to download
[INFO] 2026-01-09 14:33:43.460 Successfully downloaded 7 images
[INFO] 2026-01-09 14:34:04.415   Built content_list with 15 items
[INFO] 2026-01-09 14:34:04.415   Found 1 markdown file(s)
[INFO] 2026-01-09 14:34:04.415 
[INFO] 2026-01-09 14:34:04.415 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 14:34:05.885 Processing markdown files and embedding images...
[WARNING] 2026-01-09 14:50:13.942 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:50:16.008 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 14:50:16.011 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 14:50:18.032 mingle: searching for neighbors
[INFO] 2026-01-09 14:50:25.214 mingle: all alone
[INFO] 2026-01-09 14:50:35.465 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 14:50:57.125 Task celery_app.tasks.generate_slides_task[a2639736-a35a-403b-b608-bc29532713e0] received
[INFO] 2026-01-09 14:50:59.238 开始执行任务: a2639736-a35a-403b-b608-bc29532713e0, update_system=False
[INFO] 2026-01-09 14:50:59.238 开始执行任务: a2639736-a35a-403b-b608-bc29532713e0, update_system=False
[INFO] 2026-01-09 14:51:02.534 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 14:51:02.609 [a2639736-a35a-403b-b608-bc29532713e0] 开始参数校验...
[INFO] 2026-01-09 14:51:02.609 [a2639736-a35a-403b-b608-bc29532713e0] 开始参数校验...
[INFO] 2026-01-09 14:51:02.618 [a2639736-a35a-403b-b608-bc29532713e0] 任务状态已更新为 running
[INFO] 2026-01-09 14:51:02.618 [a2639736-a35a-403b-b608-bc29532713e0] 任务状态已更新为 running
[INFO] 2026-01-09 14:51:02.639 [a2639736-a35a-403b-b608-bc29532713e0] 开始下载文件...
[INFO] 2026-01-09 14:51:02.639 [a2639736-a35a-403b-b608-bc29532713e0] 开始下载文件...
[INFO] 2026-01-09 14:51:02.640 [a2639736-a35a-403b-b608-bc29532713e0] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:51:02.640 [a2639736-a35a-403b-b608-bc29532713e0] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 14:51:02.641 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 14:51:02.643 MinIO客户端初始化成功
[INFO] 2026-01-09 14:51:02.922 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\a2639736-a35a-403b-b608-bc29532713e0\2501.11921.md
[INFO] 2026-01-09 14:51:02.924 [a2639736-a35a-403b-b608-bc29532713e0] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\a2639736-a35a-403b-b608-bc29532713e0\2501.11921.md
[INFO] 2026-01-09 14:51:02.924 [a2639736-a35a-403b-b608-bc29532713e0] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\a2639736-a35a-403b-b608-bc29532713e0\2501.11921.md
[INFO] 2026-01-09 14:51:02.929 [a2639736-a35a-403b-b608-bc29532713e0] 开始调用生成管道...
[INFO] 2026-01-09 14:51:02.929 [a2639736-a35a-403b-b608-bc29532713e0] 开始调用生成管道...
[INFO] 2026-01-09 14:51:02.933 Starting pipeline from stage: rag
[INFO] 2026-01-09 14:51:02.933 Session ID: f8d9e0fe-af34-4a75-85b9-12204d6a7d5f
[INFO] 2026-01-09 14:51:02.935 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 14:51:02.935 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 14:51:02.941 
[INFO] 2026-01-09 14:51:02.942 Starting from stage: rag
[INFO] 2026-01-09 14:51:02.942 
[INFO] 2026-01-09 14:51:02.942 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:51:02.942 STAGE: RAG
[INFO] 2026-01-09 14:51:02.943 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:51:02.944 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 14:51:05.184 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 14:51:05.192 Found 7 external images to download
[INFO] 2026-01-09 14:51:05.433 Successfully downloaded 7 images
[INFO] 2026-01-09 14:51:05.437   Built content_list with 15 items
[INFO] 2026-01-09 14:51:05.438   Found 1 markdown file(s)
[INFO] 2026-01-09 14:51:05.439 
[INFO] 2026-01-09 14:51:05.439 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 14:51:07.432 Processing markdown files and embedding images...
[WARNING] 2026-01-09 14:52:52.815 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/8c0fbe7b8b7042b32e81652b092d18ba9592e23ac68dc3e47f650184f1aa6e52.png
[WARNING] 2026-01-09 14:52:52.817 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/3500959562fb2cb6e18c85ecd8caf910d95700bd7b619e6a5a310c3f1f0ba8cc.png
[WARNING] 2026-01-09 14:52:52.818 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/e34839d172aafb33e51cfd2474d13cb5f116c7a0390e4c3056705fa04fa80983.png
[WARNING] 2026-01-09 14:52:52.818 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/8e52fa30ffc5b4ba0465de558256e2a2a07ca6c920246abdc7fd7f9149d50cac.png
[WARNING] 2026-01-09 14:52:52.819 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/6a5c96c530308e7bf39691c193587b2f7f50a44610d8ddfa315afd574e7e54a5.png
[WARNING] 2026-01-09 14:52:52.820 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/8a4b87e4631c1ad6fe4060f5eb60fc992fd8743289d4b0e794598f05965f4711.png
[WARNING] 2026-01-09 14:52:52.820 Skipping HTTP URL image: http://61.160.97.222:59003/kb-paper-images/arxiv-2025-2501.11921/54abcbaad4d7406bc6856bb758310fa92aaa124203532d704e2bafdc65f450dd.png
[INFO] 2026-01-09 14:52:52.826   2501.11921.md: embedded 0 images
[INFO] 2026-01-09 14:52:52.827 Total embedded images: 0
[INFO] 2026-01-09 14:53:32.468   Completed 26 queries
[INFO] 2026-01-09 14:53:32.483   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 14:53:32.485 
[INFO] 2026-01-09 14:53:32.485 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:53:32.486 STAGE: SUMMARY
[INFO] 2026-01-09 14:53:32.486 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:53:33.918 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 14:53:33.918   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 14:53:36.394   Paper metadata extracted successfully
[INFO] 2026-01-09 14:53:55.487   Summary: 10644 chars
[INFO] 2026-01-09 14:53:55.487 Extracting tables and figures...
[INFO] 2026-01-09 14:53:55.491   Tables: 2, Figures: 0
[INFO] 2026-01-09 14:53:55.505   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 14:53:55.508 
[INFO] 2026-01-09 14:53:55.509 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:53:55.509 STAGE: PLAN
[INFO] 2026-01-09 14:53:55.509 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:53:55.522 Planning content...
[INFO] 2026-01-09 14:53:56.936 Calling LLM with text only (no images)
[INFO] 2026-01-09 14:53:56.936 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 14:54:09.065 LLM returned 6647 characters
[INFO] 2026-01-09 14:54:09.066 ================================================================================
[INFO] 2026-01-09 14:54:09.066 LLM Response for Content Planning:
[INFO] 2026-01-09 14:54:09.067 --------------------------------------------------------------------------------
[INFO] 2026-01-09 14:54:09.067 ```json
{
  "sections": [
    {
      "id": "poster_title",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Authors: Jiazheng Chen, Wanchun Liu* (Corresponding Author). This research addresses the critical challenge of scheduling in next-generation 6G goal-oriented communication systems, moving beyond traditional throughput maximization to application-driven objectives such as minimizing Age of Information (AoI) and state estimation error.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_motivation",
      "title": "Motivation and Research Gaps",
      "content": "The study targets the Optimal Transmission Scheduling problem where multiple edge devices share limited wireless channels. Existing methods face significant hurdles: 1) Heuristics like Whittle’s Index lack optimality guarantees. 2) Traditional Dynamic Programming suffers from the 'curse of dimensionality' in large-scale systems. 3) Standard DRL algorithms are flawed; Off-policy methods (DQN, DDPG) exhibit instability and fail to converge in scenarios with over 20 devices, while On-policy methods (PPO) suffer from low sample efficiency and often trap in local optima, resulting in performance losses up to 45%. A critical research gap exists in the lack of theoretical structural guidance (e.g., monotonicity and convexity) within DRL frameworks, which is essential for navigating high-dimensional state-action spaces where 10 devices and 5 channels can generate over 30,000 possible actions per time step.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "SUDO-DRL Framework and Mathematical Structure",
      "content": "SUDO-DRL (Structure-guided Unified Dual On-off policy DRL) integrates theoretical MDP properties into a hybrid learning architecture. The framework is built on proven properties: Critic Monotonicity (state value increa
[INFO] 2026-01-09 14:54:09.067 ... (truncated, total length: 6647 chars)
[INFO] 2026-01-09 14:54:09.068 ================================================================================
[INFO] 2026-01-09 14:54:09.068 Found JSON in code block
[INFO] 2026-01-09 14:54:09.072   Generated 6 sections:
[INFO] 2026-01-09 14:54:09.072     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 14:54:09.072     [2] Motivation and Research Gaps (content)
[INFO] 2026-01-09 14:54:09.072     [3] SUDO-DRL Framework and Mathematical Structure (content)
[INFO] 2026-01-09 14:54:09.073     [4] Technical Workflow and Structural Scoring (content)
[INFO] 2026-01-09 14:54:09.073     [5] Experimental Results and Performance Analysis (content)
[INFO] 2026-01-09 14:54:09.073     [6] Key Contributions and Findings (content)
[INFO] 2026-01-09 14:54:09.078   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 14:54:09.083 
[INFO] 2026-01-09 14:54:09.084 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:54:09.085 STAGE: GENERATE
[INFO] 2026-01-09 14:54:09.086 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:54:09.101 Generating images...
[INFO] 2026-01-09 14:54:10.514 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 14:54:10.514   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 14:54:10.515   Prompt length: 6024 chars
[INFO] 2026-01-09 14:54:45.437 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 14:54:46.001 Image generation successful (Doubao, URL, 1136718 bytes)
[INFO] 2026-01-09 14:54:46.005   [1/1] Saved: poster.png
[INFO] 2026-01-09 14:54:46.005   Generated 1 images
[INFO] 2026-01-09 14:54:46.006 
[INFO] 2026-01-09 14:54:46.006 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_145409
[INFO] 2026-01-09 14:54:46.008 
[INFO] 2026-01-09 14:54:46.008 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:54:46.008 SUMMARY
[INFO] 2026-01-09 14:54:46.009 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 14:54:46.009   [✓] rag: completed
[INFO] 2026-01-09 14:54:46.009   [✓] summary: completed
[INFO] 2026-01-09 14:54:46.010   [✓] plan: completed
[INFO] 2026-01-09 14:54:46.010   [✓] generate: completed
[INFO] 2026-01-09 14:54:46.011 [a2639736-a35a-403b-b608-bc29532713e0] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 14:54:46.011 [a2639736-a35a-403b-b608-bc29532713e0] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 14:54:46.019 [a2639736-a35a-403b-b608-bc29532713e0] 开始上传文件...
[INFO] 2026-01-09 14:54:46.019 [a2639736-a35a-403b-b608-bc29532713e0] 开始上传文件...
[INFO] 2026-01-09 14:54:46.094 已创建 MinIO bucket: kb-poster-user
[INFO] 2026-01-09 14:54:46.320 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 14:54:46.320 [a2639736-a35a-403b-b608-bc29532713e0] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 14:54:46.320 [a2639736-a35a-403b-b608-bc29532713e0] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 14:54:46.324 [a2639736-a35a-403b-b608-bc29532713e0] 开始更新用户数据...
[INFO] 2026-01-09 14:54:46.324 [a2639736-a35a-403b-b608-bc29532713e0] 开始更新用户数据...
[INFO] 2026-01-09 14:54:46.327 只更新当前任务: a2639736-a35a-403b-b608-bc29532713e0, update_system=False
[INFO] 2026-01-09 14:54:46.327 只更新当前任务: a2639736-a35a-403b-b608-bc29532713e0, update_system=False
[INFO] 2026-01-09 14:54:46.327 [a2639736-a35a-403b-b608-bc29532713e0] 用户数据更新完成
[INFO] 2026-01-09 14:54:46.327 [a2639736-a35a-403b-b608-bc29532713e0] 用户数据更新完成
[INFO] 2026-01-09 14:54:46.330 [a2639736-a35a-403b-b608-bc29532713e0] 开始更新系统数据...
[INFO] 2026-01-09 14:54:46.330 [a2639736-a35a-403b-b608-bc29532713e0] 开始更新系统数据...
[INFO] 2026-01-09 14:54:46.331 [a2639736-a35a-403b-b608-bc29532713e0] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 14:54:46.331 [a2639736-a35a-403b-b608-bc29532713e0] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 14:54:46.334 任务执行完成: a2639736-a35a-403b-b608-bc29532713e0, status=success
[INFO] 2026-01-09 14:54:46.334 任务执行完成: a2639736-a35a-403b-b608-bc29532713e0, status=success
[INFO] 2026-01-09 14:54:46.336 任务成功: a2639736-a35a-403b-b608-bc29532713e0
[INFO] 2026-01-09 14:54:46.336 任务成功: a2639736-a35a-403b-b608-bc29532713e0
[INFO] 2026-01-09 14:54:48.381 运行中任务数减少: 0
[INFO] 2026-01-09 14:54:48.384 已清理临时文件: a2639736-a35a-403b-b608-bc29532713e0
[INFO] 2026-01-09 14:54:48.384 已清理临时文件: a2639736-a35a-403b-b608-bc29532713e0
[INFO] 2026-01-09 14:54:48.387 Task celery_app.tasks.generate_slides_task[a2639736-a35a-403b-b608-bc29532713e0] succeeded in 231.26599999982864s: {'result_id': 'a2639736-a35a-403b-b608-bc29532713e0', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png', 'images': None, 'error_message': None}
[WARNING] 2026-01-09 15:29:12.975 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:29:15.045 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 15:29:15.047 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:29:19.123 mingle: searching for neighbors
[INFO] 2026-01-09 15:29:26.302 mingle: all alone
[INFO] 2026-01-09 15:29:34.482 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 15:29:34.486 Task celery_app.tasks.generate_slides_task[56039e63-de7c-4909-aac9-dadaa9a37ac4] received
[INFO] 2026-01-09 15:29:36.587 开始执行任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 15:29:36.587 开始执行任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 15:29:39.450 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 15:29:39.522 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始参数校验...
[INFO] 2026-01-09 15:29:39.522 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始参数校验...
[INFO] 2026-01-09 15:29:39.525 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 任务状态已更新为 running
[INFO] 2026-01-09 15:29:39.525 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 任务状态已更新为 running
[INFO] 2026-01-09 15:29:39.537 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始下载文件...
[INFO] 2026-01-09 15:29:39.537 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始下载文件...
[INFO] 2026-01-09 15:29:39.538 [56039e63-de7c-4909-aac9-dadaa9a37ac4] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:29:39.538 [56039e63-de7c-4909-aac9-dadaa9a37ac4] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:29:39.539 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 15:29:39.540 MinIO客户端初始化成功
[INFO] 2026-01-09 15:29:39.795 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 15:29:39.795 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 15:29:39.795 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\56039e63-de7c-4909-aac9-dadaa9a37ac4\2501.11921.md
[INFO] 2026-01-09 15:29:39.798 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始调用生成管道...
[INFO] 2026-01-09 15:29:39.798 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始调用生成管道...
[INFO] 2026-01-09 15:29:39.800 Starting pipeline from stage: generate
[INFO] 2026-01-09 15:29:39.801 Session ID: 51d8b24b-9e83-4fa2-bb95-f530373904d1
[INFO] 2026-01-09 15:29:39.801 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:29:39.801 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:29:39.807 
[INFO] 2026-01-09 15:29:39.808 Starting from stage: generate
[INFO] 2026-01-09 15:29:39.808 
[INFO] 2026-01-09 15:29:39.808 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:29:39.809 STAGE: GENERATE
[INFO] 2026-01-09 15:29:39.809 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:29:42.140 Generating images...
[INFO] 2026-01-09 15:29:44.087 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 15:29:44.090   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 15:29:44.090   Prompt length: 6024 chars
[INFO] 2026-01-09 15:30:16.918 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 15:30:17.701 Image generation successful (Doubao, URL, 1392161 bytes)
[INFO] 2026-01-09 15:30:17.705   [1/1] Saved: poster.png
[INFO] 2026-01-09 15:30:17.706   Generated 1 images
[INFO] 2026-01-09 15:30:17.706 
[INFO] 2026-01-09 15:30:17.707 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_152942
[INFO] 2026-01-09 15:30:17.710 
[INFO] 2026-01-09 15:30:17.710 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:30:17.710 SUMMARY
[INFO] 2026-01-09 15:30:17.711 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:30:17.711   [✓] rag: completed
[INFO] 2026-01-09 15:30:17.711   [✓] summary: completed
[INFO] 2026-01-09 15:30:17.712   [✓] plan: completed
[INFO] 2026-01-09 15:30:17.712   [✓] generate: completed
[INFO] 2026-01-09 15:30:17.713 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:30:17.713 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:30:17.716 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始上传文件...
[INFO] 2026-01-09 15:30:17.716 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始上传文件...
[INFO] 2026-01-09 15:30:18.159 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:30:18.159 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:30:18.159 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:30:18.163 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始更新用户数据...
[INFO] 2026-01-09 15:30:18.163 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始更新用户数据...
[INFO] 2026-01-09 15:30:18.166 只更新当前任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 15:30:18.166 只更新当前任务: 56039e63-de7c-4909-aac9-dadaa9a37ac4, update_system=False
[INFO] 2026-01-09 15:30:18.167 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 用户数据更新完成
[INFO] 2026-01-09 15:30:18.167 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 用户数据更新完成
[INFO] 2026-01-09 15:30:18.170 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始更新系统数据...
[INFO] 2026-01-09 15:30:18.170 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 开始更新系统数据...
[INFO] 2026-01-09 15:30:18.171 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:30:18.171 [56039e63-de7c-4909-aac9-dadaa9a37ac4] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:30:18.174 任务执行完成: 56039e63-de7c-4909-aac9-dadaa9a37ac4, status=success
[INFO] 2026-01-09 15:30:18.174 任务执行完成: 56039e63-de7c-4909-aac9-dadaa9a37ac4, status=success
[INFO] 2026-01-09 15:30:18.175 任务成功: 56039e63-de7c-4909-aac9-dadaa9a37ac4
[INFO] 2026-01-09 15:30:18.175 任务成功: 56039e63-de7c-4909-aac9-dadaa9a37ac4
[INFO] 2026-01-09 15:30:20.235 运行中任务数减少: 0
[INFO] 2026-01-09 15:30:20.246 已清理临时文件: 56039e63-de7c-4909-aac9-dadaa9a37ac4
[INFO] 2026-01-09 15:30:20.246 已清理临时文件: 56039e63-de7c-4909-aac9-dadaa9a37ac4
[INFO] 2026-01-09 15:30:20.256 Task celery_app.tasks.generate_slides_task[56039e63-de7c-4909-aac9-dadaa9a37ac4] succeeded in 45.7660000002943s: {'result_id': '56039e63-de7c-4909-aac9-dadaa9a37ac4', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png', 'images': None, 'error_message': None}
[INFO] 2026-01-09 15:30:40.045 Task celery_app.tasks.generate_slides_task[af1545ed-106c-4ee9-89e6-2ee4d091dc52] received
[INFO] 2026-01-09 15:30:40.049 开始执行任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 15:30:40.049 开始执行任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 15:30:40.126 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始参数校验...
[INFO] 2026-01-09 15:30:40.126 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始参数校验...
[INFO] 2026-01-09 15:30:40.134 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 任务状态已更新为 running
[INFO] 2026-01-09 15:30:40.134 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 任务状态已更新为 running
[INFO] 2026-01-09 15:30:40.138 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始下载文件...
[INFO] 2026-01-09 15:30:40.138 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始下载文件...
[INFO] 2026-01-09 15:30:40.140 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:30:40.140 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:30:40.322 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 15:30:40.323 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 15:30:40.323 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 15:30:40.327 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始调用生成管道...
[INFO] 2026-01-09 15:30:40.327 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始调用生成管道...
[INFO] 2026-01-09 15:30:40.329 Starting pipeline from stage: generate
[INFO] 2026-01-09 15:30:40.329 Session ID: f67f320b-1072-4226-b15f-e9d9439a631a
[INFO] 2026-01-09 15:30:40.330 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:30:40.330 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:30:40.332 
[INFO] 2026-01-09 15:30:40.334 Starting from stage: generate
[INFO] 2026-01-09 15:30:40.334 
[INFO] 2026-01-09 15:30:40.335 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:30:40.335 STAGE: GENERATE
[INFO] 2026-01-09 15:30:40.336 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:30:40.339 Generating images...
[INFO] 2026-01-09 15:30:42.155 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 15:30:42.156   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 15:30:42.157   Prompt length: 6024 chars
[WARNING] 2026-01-09 15:31:17.709 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:31:19.776 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 15:31:19.778 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:31:21.823 mingle: searching for neighbors
[INFO] 2026-01-09 15:31:28.946 mingle: all alone
[INFO] 2026-01-09 15:31:39.217 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 15:31:52.744 Task celery_app.tasks.generate_slides_task[30ba1706-a811-4e0b-ae70-f8416af21c44] received
[INFO] 2026-01-09 15:31:54.864 开始执行任务: 30ba1706-a811-4e0b-ae70-f8416af21c44, update_system=False
[INFO] 2026-01-09 15:31:54.864 开始执行任务: 30ba1706-a811-4e0b-ae70-f8416af21c44, update_system=False
[INFO] 2026-01-09 15:31:58.426 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 15:31:58.499 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始参数校验...
[INFO] 2026-01-09 15:31:58.499 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始参数校验...
[INFO] 2026-01-09 15:31:58.506 [30ba1706-a811-4e0b-ae70-f8416af21c44] 任务状态已更新为 running
[INFO] 2026-01-09 15:31:58.506 [30ba1706-a811-4e0b-ae70-f8416af21c44] 任务状态已更新为 running
[INFO] 2026-01-09 15:31:58.513 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始下载文件...
[INFO] 2026-01-09 15:31:58.513 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始下载文件...
[INFO] 2026-01-09 15:31:58.514 [30ba1706-a811-4e0b-ae70-f8416af21c44] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:31:58.514 [30ba1706-a811-4e0b-ae70-f8416af21c44] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:31:58.515 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 15:31:58.516 MinIO客户端初始化成功
[INFO] 2026-01-09 15:31:58.773 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\30ba1706-a811-4e0b-ae70-f8416af21c44\2501.11921.md
[INFO] 2026-01-09 15:31:58.773 [30ba1706-a811-4e0b-ae70-f8416af21c44] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\30ba1706-a811-4e0b-ae70-f8416af21c44\2501.11921.md
[INFO] 2026-01-09 15:31:58.773 [30ba1706-a811-4e0b-ae70-f8416af21c44] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\30ba1706-a811-4e0b-ae70-f8416af21c44\2501.11921.md
[INFO] 2026-01-09 15:31:58.779 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始调用生成管道...
[INFO] 2026-01-09 15:31:58.779 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始调用生成管道...
[INFO] 2026-01-09 15:31:58.782 Starting pipeline from stage: rag
[INFO] 2026-01-09 15:31:58.782 Session ID: 18257412-63e0-421b-92b7-a4609ad30606
[INFO] 2026-01-09 15:31:58.783 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:31:58.783 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:31:58.787 
[INFO] 2026-01-09 15:31:58.788 Starting from stage: rag
[INFO] 2026-01-09 15:31:58.788 
[INFO] 2026-01-09 15:31:58.789 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:31:58.789 STAGE: RAG
[INFO] 2026-01-09 15:31:58.789 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:31:58.793 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 15:32:01.717 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 15:32:01.722 Found 7 external images to download
[INFO] 2026-01-09 15:32:01.911 Successfully downloaded 7 images
[INFO] 2026-01-09 15:32:01.913   Built content_list with 15 items
[INFO] 2026-01-09 15:32:01.913   Found 1 markdown file(s)
[INFO] 2026-01-09 15:32:01.914 
[INFO] 2026-01-09 15:32:01.914 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 15:32:04.223 Processing markdown files and embedding images...
[INFO] 2026-01-09 15:33:42.355   2501.11921.md: embedded 7 images
[INFO] 2026-01-09 15:33:42.355 Total embedded images: 7
[ERROR] 2026-01-09 15:33:44.304 Query failed: List the paper title, author names and their insti... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.395 Query failed: Describe the architecture or framework diagram. Wh... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.457 Query failed: What problem or task does this paper aim to solve?... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.511 Query failed: What are the limitations or drawbacks of existing ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.700 Query failed: What gap or unmet need motivates this research? Ho... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.793 Query failed: Show any dataset statistics table with sizes, spli... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.843 Query failed: Show the main performance comparison table with al... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:44.924 Query failed: Show the ablation study table with all variants an... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.175 Query failed: What method, approach, or framework does this pape... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.279 Query failed: Describe the system design, model structure, or th... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.463 Query failed: What is the core model formulation or main equatio... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.465 Query failed: What objective function, optimization goal, or the... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.493 Query failed: What are the main components, modules, or steps of... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.620 Query failed: What is the algorithm, procedure, or workflow? Des... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.622 Query failed: What datasets, benchmarks, or experimental setups ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:45.841 Query failed: What are the key equations, formulas, or mathemati... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.096 Query failed: How does the proposed method compare to baseline m... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.132 Query failed: What are the key parameters, settings, or implemen... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.302 Query failed: What evaluation metrics or criteria are used to me... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.435 Query failed: What analysis, case study, or discussion of the re... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.575 Query failed: What ablation study or sensitivity analysis is con... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.694 Query failed: What are the main results shown in the main result... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.832 Query failed: What limitations does the paper acknowledge? What ... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:46.941 Query failed: What are the main contributions listed in the intr... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:47.051 Query failed: What performance does the method achieve? Report t... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[ERROR] 2026-01-09 15:33:47.634 Query failed: What is novel or new about this work compared to e... Error: Error code: 400 - {'error': {'message': '获取模型实例信息失败: No model instance data found', 'type': 'invalid_model_instance'}}
[INFO] 2026-01-09 15:33:47.635   Completed 26 queries
[INFO] 2026-01-09 15:33:47.658   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 15:33:47.660 
[INFO] 2026-01-09 15:33:47.660 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:33:47.660 STAGE: SUMMARY
[INFO] 2026-01-09 15:33:47.660 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:33:49.912 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 15:33:49.912   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 15:33:53.483   Paper metadata extracted successfully
[INFO] 2026-01-09 15:33:53.487   Summary: 186 chars
[INFO] 2026-01-09 15:33:53.488 Extracting tables and figures...
[INFO] 2026-01-09 15:33:53.497   Tables: 2, Figures: 0
[INFO] 2026-01-09 15:33:53.513   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 15:33:53.516 
[INFO] 2026-01-09 15:33:53.516 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:33:53.518 STAGE: PLAN
[INFO] 2026-01-09 15:33:53.518 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:33:53.535 Planning content...
[INFO] 2026-01-09 15:33:55.372 Calling LLM with text only (no images)
[INFO] 2026-01-09 15:33:55.372 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 15:34:09.723 LLM returned 6067 characters
[INFO] 2026-01-09 15:34:09.724 ================================================================================
[INFO] 2026-01-09 15:34:09.725 LLM Response for Content Planning:
[INFO] 2026-01-09 15:34:09.726 --------------------------------------------------------------------------------
[INFO] 2026-01-09 15:34:09.726 ```json
{
  "sections": [
    {
      "id": "poster_header",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Authors: Jiazheng Chen, Wanchun Liu*. This research addresses the critical challenge of scheduling in goal-oriented communication systems where the objective is to minimize the long-term average cost associated with information freshness and transmission reliability. The work introduces SUDO-DRL, a novel framework designed to handle large-scale state and action spaces by integrating the structural properties of optimal policies with a hybrid reinforcement learning approach.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_background",
      "title": "Background and Motivation",
      "content": "In goal-oriented communications, traditional metrics like throughput are replaced by Age of Information (AoI) and cost-of-update to ensure timely delivery of status updates. Existing Deep Reinforcement Learning (DRL) methods, such as Deep Deterministic Policy Gradient (DDPG) and Proximal Policy Optimization (PPO), face significant limitations in these scenarios. Specifically, they suffer from slow convergence and poor scalability as the number of devices (N) and channels (M) increases. The 'curse of dimensionality' in the action space makes it difficult for standard agents to explore effectively. There is a pressing need for a scheduling framework that can leverage the inherent mathematical structure of the optimal policy—often characterized by threshold-based or monotonic properties—to guide the learning process and improve efficiency in high-dimensional environments.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "Methodology: The SUDO-DRL Framework",
      "content": "The SUDO-DRL (Structure-guided Unified Dual On-policy and Off-policy) framework consists of two core innovations. Fir
[INFO] 2026-01-09 15:34:09.727 ... (truncated, total length: 6067 chars)
[INFO] 2026-01-09 15:34:09.727 ================================================================================
[INFO] 2026-01-09 15:34:09.728 Found JSON in code block
[INFO] 2026-01-09 15:34:09.733   Generated 5 sections:
[INFO] 2026-01-09 15:34:09.733     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 15:34:09.733     [2] Background and Motivation (content)
[INFO] 2026-01-09 15:34:09.734     [3] Methodology: The SUDO-DRL Framework (content)
[INFO] 2026-01-09 15:34:09.734     [4] Experimental Results and Performance Analysis (content)
[INFO] 2026-01-09 15:34:09.734     [5] Conclusion and Key Contributions (content)
[INFO] 2026-01-09 15:34:09.739   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 15:34:09.742 
[INFO] 2026-01-09 15:34:09.744 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:34:09.745 STAGE: GENERATE
[INFO] 2026-01-09 15:34:09.746 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:34:09.767 Generating images...
[INFO] 2026-01-09 15:34:11.734 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 15:34:11.735   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 15:34:11.735   Prompt length: 5625 chars
[INFO] 2026-01-09 15:34:59.802 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 15:35:00.376 Image generation successful (Doubao, URL, 1320346 bytes)
[INFO] 2026-01-09 15:35:00.379   [1/1] Saved: poster.png
[INFO] 2026-01-09 15:35:00.379   Generated 1 images
[INFO] 2026-01-09 15:35:00.379 
[INFO] 2026-01-09 15:35:00.380 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_153409
[INFO] 2026-01-09 15:35:00.383 
[INFO] 2026-01-09 15:35:00.383 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:35:00.383 SUMMARY
[INFO] 2026-01-09 15:35:00.384 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:35:00.384   [✓] rag: completed
[INFO] 2026-01-09 15:35:00.384   [✓] summary: completed
[INFO] 2026-01-09 15:35:00.384   [✓] plan: completed
[INFO] 2026-01-09 15:35:00.385   [✓] generate: completed
[INFO] 2026-01-09 15:35:00.386 [30ba1706-a811-4e0b-ae70-f8416af21c44] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:35:00.386 [30ba1706-a811-4e0b-ae70-f8416af21c44] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:35:00.392 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始上传文件...
[INFO] 2026-01-09 15:35:00.392 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始上传文件...
[INFO] 2026-01-09 15:35:00.750 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:35:00.750 [30ba1706-a811-4e0b-ae70-f8416af21c44] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:35:00.750 [30ba1706-a811-4e0b-ae70-f8416af21c44] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:35:00.756 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始更新用户数据...
[INFO] 2026-01-09 15:35:00.756 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始更新用户数据...
[INFO] 2026-01-09 15:35:00.761 只更新当前任务: 30ba1706-a811-4e0b-ae70-f8416af21c44, update_system=False
[INFO] 2026-01-09 15:35:00.761 只更新当前任务: 30ba1706-a811-4e0b-ae70-f8416af21c44, update_system=False
[INFO] 2026-01-09 15:35:00.762 [30ba1706-a811-4e0b-ae70-f8416af21c44] 用户数据更新完成
[INFO] 2026-01-09 15:35:00.762 [30ba1706-a811-4e0b-ae70-f8416af21c44] 用户数据更新完成
[INFO] 2026-01-09 15:35:00.768 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始更新系统数据...
[INFO] 2026-01-09 15:35:00.768 [30ba1706-a811-4e0b-ae70-f8416af21c44] 开始更新系统数据...
[INFO] 2026-01-09 15:35:00.769 [30ba1706-a811-4e0b-ae70-f8416af21c44] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:35:00.769 [30ba1706-a811-4e0b-ae70-f8416af21c44] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:35:00.772 任务执行完成: 30ba1706-a811-4e0b-ae70-f8416af21c44, status=success
[INFO] 2026-01-09 15:35:00.772 任务执行完成: 30ba1706-a811-4e0b-ae70-f8416af21c44, status=success
[INFO] 2026-01-09 15:35:00.774 任务成功: 30ba1706-a811-4e0b-ae70-f8416af21c44
[INFO] 2026-01-09 15:35:00.774 任务成功: 30ba1706-a811-4e0b-ae70-f8416af21c44
[INFO] 2026-01-09 15:35:02.838 运行中任务数减少: 0
[INFO] 2026-01-09 15:35:02.840 已清理临时文件: 30ba1706-a811-4e0b-ae70-f8416af21c44
[INFO] 2026-01-09 15:35:02.840 已清理临时文件: 30ba1706-a811-4e0b-ae70-f8416af21c44
[INFO] 2026-01-09 15:35:02.843 Task celery_app.tasks.generate_slides_task[30ba1706-a811-4e0b-ae70-f8416af21c44] succeeded in 190.09400000004098s: {'result_id': '30ba1706-a811-4e0b-ae70-f8416af21c44', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png', 'images': None, 'error_message': None}
[WARNING] 2026-01-09 15:35:58.079 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:36:00.137 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 15:36:00.140 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:36:02.176 mingle: searching for neighbors
[INFO] 2026-01-09 15:36:09.342 mingle: all alone
[INFO] 2026-01-09 15:36:19.599 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 15:36:19.610 Task celery_app.tasks.generate_slides_task[b9bd2879-d3da-48e2-811e-8e30cb41668f] received
[INFO] 2026-01-09 15:36:21.755 开始执行任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 15:36:21.755 开始执行任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 15:36:25.111 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 15:36:25.193 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始参数校验...
[INFO] 2026-01-09 15:36:25.193 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始参数校验...
[INFO] 2026-01-09 15:36:25.202 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 任务状态已更新为 running
[INFO] 2026-01-09 15:36:25.202 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 任务状态已更新为 running
[INFO] 2026-01-09 15:36:25.213 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始下载文件...
[INFO] 2026-01-09 15:36:25.213 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始下载文件...
[INFO] 2026-01-09 15:36:25.215 [b9bd2879-d3da-48e2-811e-8e30cb41668f] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:36:25.215 [b9bd2879-d3da-48e2-811e-8e30cb41668f] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:36:25.216 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 15:36:25.217 MinIO客户端初始化成功
[INFO] 2026-01-09 15:36:25.783 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 15:36:25.784 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 15:36:25.784 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\b9bd2879-d3da-48e2-811e-8e30cb41668f\2501.11921.md
[INFO] 2026-01-09 15:36:25.789 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始调用生成管道...
[INFO] 2026-01-09 15:36:25.789 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始调用生成管道...
[INFO] 2026-01-09 15:36:25.792 Starting pipeline from stage: rag
[INFO] 2026-01-09 15:36:25.793 Session ID: 3cd905e4-313c-4a16-9ec3-d1e7088eeecc
[INFO] 2026-01-09 15:36:25.794 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:36:25.795 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:36:25.804 
[INFO] 2026-01-09 15:36:25.805 Starting from stage: rag
[INFO] 2026-01-09 15:36:25.806 
[INFO] 2026-01-09 15:36:25.806 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:36:25.806 STAGE: RAG
[INFO] 2026-01-09 15:36:25.807 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:36:25.809 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 15:36:28.672 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 15:36:28.675 Found 7 external images to download
[INFO] 2026-01-09 15:36:28.909 Successfully downloaded 7 images
[INFO] 2026-01-09 15:36:28.912   Built content_list with 15 items
[INFO] 2026-01-09 15:36:28.912   Found 1 markdown file(s)
[INFO] 2026-01-09 15:36:28.912 
[INFO] 2026-01-09 15:36:28.913 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 15:36:31.020 Processing markdown files and embedding images...
[INFO] 2026-01-09 15:36:31.032   2501.11921.md: embedded 7 images
[INFO] 2026-01-09 15:36:31.032 Total embedded images: 7
[INFO] 2026-01-09 15:38:02.454   Completed 26 queries
[INFO] 2026-01-09 15:38:02.492   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 15:38:02.496 
[INFO] 2026-01-09 15:38:02.496 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:02.498 STAGE: SUMMARY
[INFO] 2026-01-09 15:38:02.498 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:04.697 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 15:38:04.698   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 15:38:07.246   Paper metadata extracted successfully
[INFO] 2026-01-09 15:38:24.450   Summary: 10210 chars
[INFO] 2026-01-09 15:38:24.452 Extracting tables and figures...
[INFO] 2026-01-09 15:38:24.471   Tables: 2, Figures: 0
[INFO] 2026-01-09 15:38:24.499   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 15:38:24.501 
[INFO] 2026-01-09 15:38:24.501 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:24.501 STAGE: PLAN
[INFO] 2026-01-09 15:38:24.501 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:24.528 Planning content...
[INFO] 2026-01-09 15:38:26.265 Calling LLM with text only (no images)
[INFO] 2026-01-09 15:38:26.266 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 15:38:36.641 LLM returned 5569 characters
[INFO] 2026-01-09 15:38:36.642 ================================================================================
[INFO] 2026-01-09 15:38:36.642 LLM Response for Content Planning:
[INFO] 2026-01-09 15:38:36.643 --------------------------------------------------------------------------------
[INFO] 2026-01-09 15:38:36.643 ```json
{
  "sections": [
    {
      "id": "poster_title",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Authors: Jiazheng Chen, Wanchun Liu*. This research addresses the critical challenge of multi-device, multi-channel wireless communication scheduling. Unlike traditional bit-accurate communication, this work prioritizes application-driven goals such as timeliness and relevance, specifically utilizing Age of Information (AoI) as a core metric for remote state estimation systems.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_motivation",
      "title": "Motivation and Research Gaps",
      "content": "Traditional scheduling methods face severe limitations in large-scale systems. Dynamic programming suffers from computational infeasibility due to the 'curse of dimensionality' (e.g., 30,240 action combinations for 10 devices). Heuristic methods like Whittle's Index lack optimality guarantees. General DRL often falls into local optima and lacks structural insights. Specifically, Off-policy DRL (DQN, DDPG) exhibits instability and fails to converge in scenarios with 40 devices and 20 channels, while On-policy DRL (PPO) suffers from low sample efficiency and significant performance loss in large-scale environments. There is a clear gap for a solution that maintains stability while leveraging high sample efficiency and physical structural guidance.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "SUDO-DRL Framework and Mathematical Structure",
      "content": "The SUDO-DRL (Structure-guided Unified Dual On-off policy DRL) framework integrates theoretical structural properties into a hybrid learning architecture. It utilizes a Structural Property Evaluation Framework to calculate scores for Critic-Monotonicity (CM), Critic-Convexity (CC), and Actor-Monotonicity (AM). The system dynami
[INFO] 2026-01-09 15:38:36.643 ... (truncated, total length: 5569 chars)
[INFO] 2026-01-09 15:38:36.643 ================================================================================
[INFO] 2026-01-09 15:38:36.644 Found JSON in code block
[INFO] 2026-01-09 15:38:36.647   Generated 5 sections:
[INFO] 2026-01-09 15:38:36.648     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 15:38:36.649     [2] Motivation and Research Gaps (content)
[INFO] 2026-01-09 15:38:36.649     [3] SUDO-DRL Framework and Mathematical Structure (content)
[INFO] 2026-01-09 15:38:36.649     [4] Experimental Evaluation and Scalability (content)
[INFO] 2026-01-09 15:38:36.649     [5] Conclusions and Key Contributions (content)
[INFO] 2026-01-09 15:38:36.655   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 15:38:36.658 
[INFO] 2026-01-09 15:38:36.658 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:36.659 STAGE: GENERATE
[INFO] 2026-01-09 15:38:36.659 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:38:36.678 Generating images...
[INFO] 2026-01-09 15:38:38.358 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 15:38:38.358   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 15:38:38.358   Prompt length: 5090 chars
[INFO] 2026-01-09 15:39:22.509 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 15:39:23.377 Image generation successful (Doubao, URL, 1216642 bytes)
[INFO] 2026-01-09 15:39:23.380   [1/1] Saved: poster.png
[INFO] 2026-01-09 15:39:23.380   Generated 1 images
[INFO] 2026-01-09 15:39:23.380 
[INFO] 2026-01-09 15:39:23.381 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_153836
[INFO] 2026-01-09 15:39:23.382 
[INFO] 2026-01-09 15:39:23.383 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:39:23.383 SUMMARY
[INFO] 2026-01-09 15:39:23.383 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:39:23.383   [✓] rag: completed
[INFO] 2026-01-09 15:39:23.383   [✓] summary: completed
[INFO] 2026-01-09 15:39:23.384   [✓] plan: completed
[INFO] 2026-01-09 15:39:23.384   [✓] generate: completed
[INFO] 2026-01-09 15:39:23.385 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:39:23.385 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:39:23.392 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始上传文件...
[INFO] 2026-01-09 15:39:23.392 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始上传文件...
[INFO] 2026-01-09 15:39:23.695 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:39:23.696 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:39:23.696 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:39:23.707 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始更新用户数据...
[INFO] 2026-01-09 15:39:23.707 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始更新用户数据...
[INFO] 2026-01-09 15:39:23.716 只更新当前任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 15:39:23.716 只更新当前任务: b9bd2879-d3da-48e2-811e-8e30cb41668f, update_system=False
[INFO] 2026-01-09 15:39:23.717 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 用户数据更新完成
[INFO] 2026-01-09 15:39:23.717 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 用户数据更新完成
[INFO] 2026-01-09 15:39:23.721 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始更新系统数据...
[INFO] 2026-01-09 15:39:23.721 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 开始更新系统数据...
[INFO] 2026-01-09 15:39:23.722 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:39:23.722 [b9bd2879-d3da-48e2-811e-8e30cb41668f] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:39:23.724 任务执行完成: b9bd2879-d3da-48e2-811e-8e30cb41668f, status=success
[INFO] 2026-01-09 15:39:23.724 任务执行完成: b9bd2879-d3da-48e2-811e-8e30cb41668f, status=success
[INFO] 2026-01-09 15:39:23.726 任务成功: b9bd2879-d3da-48e2-811e-8e30cb41668f
[INFO] 2026-01-09 15:39:23.726 任务成功: b9bd2879-d3da-48e2-811e-8e30cb41668f
[INFO] 2026-01-09 15:39:25.790 运行中任务数减少: 0
[INFO] 2026-01-09 15:39:25.792 已清理临时文件: b9bd2879-d3da-48e2-811e-8e30cb41668f
[INFO] 2026-01-09 15:39:25.792 已清理临时文件: b9bd2879-d3da-48e2-811e-8e30cb41668f
[INFO] 2026-01-09 15:39:25.795 Task celery_app.tasks.generate_slides_task[b9bd2879-d3da-48e2-811e-8e30cb41668f] succeeded in 186.18800000008196s: {'result_id': 'b9bd2879-d3da-48e2-811e-8e30cb41668f', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png', 'images': None, 'error_message': None}
[WARNING] 2026-01-09 15:41:38.853 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:41:40.883 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 15:41:40.885 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:41:42.925 mingle: searching for neighbors
[INFO] 2026-01-09 15:41:50.055 mingle: all alone
[INFO] 2026-01-09 15:42:00.244 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 15:42:13.432 Task celery_app.tasks.generate_slides_task[4d4be986-d46c-4560-af09-76111959d621] received
[INFO] 2026-01-09 15:42:15.527 开始执行任务: 4d4be986-d46c-4560-af09-76111959d621, update_system=False
[INFO] 2026-01-09 15:42:15.527 开始执行任务: 4d4be986-d46c-4560-af09-76111959d621, update_system=False
[INFO] 2026-01-09 15:42:16.671 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 15:42:16.694 [4d4be986-d46c-4560-af09-76111959d621] 开始参数校验...
[INFO] 2026-01-09 15:42:16.694 [4d4be986-d46c-4560-af09-76111959d621] 开始参数校验...
[INFO] 2026-01-09 15:42:16.698 [4d4be986-d46c-4560-af09-76111959d621] 任务状态已更新为 running
[INFO] 2026-01-09 15:42:16.698 [4d4be986-d46c-4560-af09-76111959d621] 任务状态已更新为 running
[INFO] 2026-01-09 15:42:16.701 [4d4be986-d46c-4560-af09-76111959d621] 开始下载文件...
[INFO] 2026-01-09 15:42:16.701 [4d4be986-d46c-4560-af09-76111959d621] 开始下载文件...
[INFO] 2026-01-09 15:42:16.703 [4d4be986-d46c-4560-af09-76111959d621] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:42:16.703 [4d4be986-d46c-4560-af09-76111959d621] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:42:16.704 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 15:42:16.705 MinIO客户端初始化成功
[INFO] 2026-01-09 15:42:16.985 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\4d4be986-d46c-4560-af09-76111959d621\2501.11921.md
[INFO] 2026-01-09 15:42:16.986 [4d4be986-d46c-4560-af09-76111959d621] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\4d4be986-d46c-4560-af09-76111959d621\2501.11921.md
[INFO] 2026-01-09 15:42:16.986 [4d4be986-d46c-4560-af09-76111959d621] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\4d4be986-d46c-4560-af09-76111959d621\2501.11921.md
[INFO] 2026-01-09 15:42:16.989 [4d4be986-d46c-4560-af09-76111959d621] 开始调用生成管道...
[INFO] 2026-01-09 15:42:16.989 [4d4be986-d46c-4560-af09-76111959d621] 开始调用生成管道...
[INFO] 2026-01-09 15:42:16.991 Starting pipeline from stage: rag
[INFO] 2026-01-09 15:42:16.991 Session ID: 467b5b3c-22a6-4888-a65f-0c7d81f0d9f0
[INFO] 2026-01-09 15:42:16.992 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:42:16.992 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:42:16.994 
[INFO] 2026-01-09 15:42:16.995 Starting from stage: rag
[INFO] 2026-01-09 15:42:16.995 
[INFO] 2026-01-09 15:42:16.995 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:42:16.996 STAGE: RAG
[INFO] 2026-01-09 15:42:16.996 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:42:16.998 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 15:42:18.098 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 15:42:18.099 Found 7 external images to download
[INFO] 2026-01-09 15:42:18.290 Successfully downloaded 7 images
[INFO] 2026-01-09 15:42:18.292   Built content_list with 15 items
[INFO] 2026-01-09 15:42:18.293   Found 1 markdown file(s)
[INFO] 2026-01-09 15:42:18.293 
[INFO] 2026-01-09 15:42:18.293 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 15:42:20.112 Processing markdown files and embedding images...
[INFO] 2026-01-09 15:42:20.137   2501.11921.md: embedded 7 images
[INFO] 2026-01-09 15:42:20.138 Total embedded images: 7
[INFO] 2026-01-09 15:43:05.929 Retrying request to /chat/completions in 0.467806 seconds
[INFO] 2026-01-09 15:43:19.641   Completed 26 queries
[INFO] 2026-01-09 15:43:19.648   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 15:43:19.650 
[INFO] 2026-01-09 15:43:19.651 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:19.652 STAGE: SUMMARY
[INFO] 2026-01-09 15:43:19.653 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:21.639 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 15:43:21.641   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 15:43:23.925   Paper metadata extracted successfully
[INFO] 2026-01-09 15:43:39.031   Summary: 10910 chars
[INFO] 2026-01-09 15:43:39.032 Extracting tables and figures...
[INFO] 2026-01-09 15:43:39.042   Tables: 2, Figures: 0
[INFO] 2026-01-09 15:43:39.049   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 15:43:39.052 
[INFO] 2026-01-09 15:43:39.052 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:39.053 STAGE: PLAN
[INFO] 2026-01-09 15:43:39.053 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:39.091 Planning content...
[INFO] 2026-01-09 15:43:40.958 Calling LLM with text only (no images)
[INFO] 2026-01-09 15:43:40.958 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 15:43:53.005 LLM returned 5781 characters
[INFO] 2026-01-09 15:43:53.005 ================================================================================
[INFO] 2026-01-09 15:43:53.005 LLM Response for Content Planning:
[INFO] 2026-01-09 15:43:53.006 --------------------------------------------------------------------------------
[INFO] 2026-01-09 15:43:53.006 ```json
{
  "sections": [
    {
      "id": "poster_title",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Jiazheng Chen and Wanchun Liu* (Corresponding Author). This research addresses the critical challenge of efficient transmission scheduling in goal-oriented communication systems, specifically focusing on large-scale wireless networks where traditional deep reinforcement learning (DRL) methods often fail to converge or exhibit poor sample efficiency.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_motivation",
      "title": "Research Motivation & Challenges",
      "content": "The study addresses the transmission scheduling problem in goal-oriented systems where $N$ devices compete for $M$ channels ($M < N$). Unlike traditional communications, the priority is Information Timeliness (Age of Information, AoI) and relevance. Existing methods face significant hurdles: 1) Heuristics like Whittle’s Index lack optimality; 2) Conventional DP suffers from the 'curse of dimensionality' in systems as small as 10 devices; 3) Standard DRL algorithms exhibit a trade-off where Off-policy DRL (DQN, SAC) is unstable and fails to converge in large-scale scenarios (30-40 devices), while On-policy DRL (PPO) is sample-inefficient and prone to local optima. There is a distinct research gap in proving mathematical properties like asymptotic convexity for AoI-based value functions and integrating these structural insights into a unified training framework that scales to 6G-level complexity (e.g., 40 devices/20 channels).",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "SUDO-DRL Framework & Structural Guidance",
      "content": "The SUDO-DRL (Structure-guided Unified Dual On-off policy DRL) framework integrates theoretical structural properties into a hybrid learning architecture. It consists of four c
[INFO] 2026-01-09 15:43:53.006 ... (truncated, total length: 5781 chars)
[INFO] 2026-01-09 15:43:53.006 ================================================================================
[INFO] 2026-01-09 15:43:53.007 Found JSON in code block
[INFO] 2026-01-09 15:43:53.008   Generated 5 sections:
[INFO] 2026-01-09 15:43:53.009     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 15:43:53.009     [2] Research Motivation & Challenges (content)
[INFO] 2026-01-09 15:43:53.009     [3] SUDO-DRL Framework & Structural Guidance (content)
[INFO] 2026-01-09 15:43:53.009     [4] Experimental Evaluation & Scalability (content)
[INFO] 2026-01-09 15:43:53.009     [5] Key Contributions (content)
[INFO] 2026-01-09 15:43:53.011   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 15:43:53.012 
[INFO] 2026-01-09 15:43:53.012 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:53.012 STAGE: GENERATE
[INFO] 2026-01-09 15:43:53.013 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:43:53.026 Generating images...
[INFO] 2026-01-09 15:43:54.685 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 15:43:54.686   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 15:43:54.686   Prompt length: 5274 chars
[INFO] 2026-01-09 15:44:32.548 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 15:44:33.393 Image generation successful (Doubao, URL, 1262847 bytes)
[INFO] 2026-01-09 15:44:33.396   [1/1] Saved: poster.png
[INFO] 2026-01-09 15:44:33.397   Generated 1 images
[INFO] 2026-01-09 15:44:33.397 
[INFO] 2026-01-09 15:44:33.398 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_154353
[INFO] 2026-01-09 15:44:33.399 
[INFO] 2026-01-09 15:44:33.400 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:44:33.400 SUMMARY
[INFO] 2026-01-09 15:44:33.400 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:44:33.401   [✓] rag: completed
[INFO] 2026-01-09 15:44:33.401   [✓] summary: completed
[INFO] 2026-01-09 15:44:33.401   [✓] plan: completed
[INFO] 2026-01-09 15:44:33.402   [✓] generate: completed
[INFO] 2026-01-09 15:44:33.403 [4d4be986-d46c-4560-af09-76111959d621] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:44:33.403 [4d4be986-d46c-4560-af09-76111959d621] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 15:44:33.404 [4d4be986-d46c-4560-af09-76111959d621] 开始上传文件...
[INFO] 2026-01-09 15:44:33.404 [4d4be986-d46c-4560-af09-76111959d621] 开始上传文件...
[INFO] 2026-01-09 15:44:33.739 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:44:33.740 [4d4be986-d46c-4560-af09-76111959d621] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:44:33.740 [4d4be986-d46c-4560-af09-76111959d621] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png
[INFO] 2026-01-09 15:44:33.746 [4d4be986-d46c-4560-af09-76111959d621] 开始更新用户数据...
[INFO] 2026-01-09 15:44:33.746 [4d4be986-d46c-4560-af09-76111959d621] 开始更新用户数据...
[INFO] 2026-01-09 15:44:33.754 只更新当前任务: 4d4be986-d46c-4560-af09-76111959d621, update_system=False
[INFO] 2026-01-09 15:44:33.754 只更新当前任务: 4d4be986-d46c-4560-af09-76111959d621, update_system=False
[INFO] 2026-01-09 15:44:33.756 [4d4be986-d46c-4560-af09-76111959d621] 用户数据更新完成
[INFO] 2026-01-09 15:44:33.756 [4d4be986-d46c-4560-af09-76111959d621] 用户数据更新完成
[INFO] 2026-01-09 15:44:33.760 [4d4be986-d46c-4560-af09-76111959d621] 开始更新系统数据...
[INFO] 2026-01-09 15:44:33.760 [4d4be986-d46c-4560-af09-76111959d621] 开始更新系统数据...
[INFO] 2026-01-09 15:44:33.763 [4d4be986-d46c-4560-af09-76111959d621] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:44:33.763 [4d4be986-d46c-4560-af09-76111959d621] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 15:44:33.769 任务执行完成: 4d4be986-d46c-4560-af09-76111959d621, status=success
[INFO] 2026-01-09 15:44:33.769 任务执行完成: 4d4be986-d46c-4560-af09-76111959d621, status=success
[INFO] 2026-01-09 15:44:33.771 任务成功: 4d4be986-d46c-4560-af09-76111959d621
[INFO] 2026-01-09 15:44:33.771 任务成功: 4d4be986-d46c-4560-af09-76111959d621
[INFO] 2026-01-09 15:44:35.801 运行中任务数减少: 0
[INFO] 2026-01-09 15:44:35.806 已清理临时文件: 4d4be986-d46c-4560-af09-76111959d621
[INFO] 2026-01-09 15:44:35.806 已清理临时文件: 4d4be986-d46c-4560-af09-76111959d621
[INFO] 2026-01-09 15:44:35.811 Task celery_app.tasks.generate_slides_task[4d4be986-d46c-4560-af09-76111959d621] succeeded in 142.375s: {'result_id': '4d4be986-d46c-4560-af09-76111959d621', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/poster.png', 'images': None, 'error_message': None}
[WARNING] 2026-01-09 15:58:26.380 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:58:28.423 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 15:58:28.425 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 15:58:30.457 mingle: searching for neighbors
[INFO] 2026-01-09 15:58:37.625 mingle: all alone
[INFO] 2026-01-09 15:58:47.919 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 15:59:51.194 Task celery_app.tasks.generate_slides_task[1b9a609e-fce7-49de-a3fc-cb828a2de68b] received
[INFO] 2026-01-09 15:59:53.304 开始执行任务: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, update_system=False
[INFO] 2026-01-09 15:59:53.304 开始执行任务: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, update_system=False
[INFO] 2026-01-09 15:59:56.409 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 15:59:56.484 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始参数校验...
[INFO] 2026-01-09 15:59:56.484 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始参数校验...
[INFO] 2026-01-09 15:59:56.488 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 任务状态已更新为 running
[INFO] 2026-01-09 15:59:56.488 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 任务状态已更新为 running
[INFO] 2026-01-09 15:59:56.493 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始下载文件...
[INFO] 2026-01-09 15:59:56.493 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始下载文件...
[INFO] 2026-01-09 15:59:56.494 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:59:56.494 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 15:59:56.494 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 15:59:56.495 MinIO客户端初始化成功
[INFO] 2026-01-09 15:59:56.778 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\1b9a609e-fce7-49de-a3fc-cb828a2de68b\2501.11921.md
[INFO] 2026-01-09 15:59:56.780 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\1b9a609e-fce7-49de-a3fc-cb828a2de68b\2501.11921.md
[INFO] 2026-01-09 15:59:56.780 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\1b9a609e-fce7-49de-a3fc-cb828a2de68b\2501.11921.md
[INFO] 2026-01-09 15:59:56.789 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始调用生成管道...
[INFO] 2026-01-09 15:59:56.789 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始调用生成管道...
[INFO] 2026-01-09 15:59:56.794 Starting pipeline from stage: rag
[INFO] 2026-01-09 15:59:56.794 Session ID: 9da5cb41-7541-45c6-99d5-d5ef913effab
[INFO] 2026-01-09 15:59:56.795 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 15:59:56.796 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 15:59:56.800 
[INFO] 2026-01-09 15:59:56.800 Starting from stage: rag
[INFO] 2026-01-09 15:59:56.800 
[INFO] 2026-01-09 15:59:56.800 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:59:56.801 STAGE: RAG
[INFO] 2026-01-09 15:59:56.801 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 15:59:56.803 Running in FAST mode (parse only, no indexing)
[INFO] 2026-01-09 15:59:59.149 PARSER_ENABLED=False, processing MD file directly: 2501.11921.md
[INFO] 2026-01-09 15:59:59.152 Found 7 external images to download
[INFO] 2026-01-09 15:59:59.392 Successfully downloaded 7 images
[INFO] 2026-01-09 15:59:59.396   Built content_list with 15 items
[INFO] 2026-01-09 15:59:59.397   Found 1 markdown file(s)
[INFO] 2026-01-09 15:59:59.399 
[INFO] 2026-01-09 15:59:59.400 Running queries with GPT-4o and images (paper)...
[INFO] 2026-01-09 16:00:01.595 Processing markdown files and embedding images...
[INFO] 2026-01-09 16:00:01.611   2501.11921.md: embedded 7 images
[INFO] 2026-01-09 16:00:01.611 Total embedded images: 7
[INFO] 2026-01-09 16:00:16.196 Query answer: Based on the provided document, here are the details requested:

*   **Paper Title:** Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach
*   **Author Names:**
    *   Jiazheng Chen
    *   Wanchun Liu
*   **Institutional Affiliation:**
    *   Both authors are affiliated with the **IEEE** (Institute of Electrical and Electronics Engineers). Specifically, Jiazheng Chen is a Graduate Student Member, and Wanchun Liu is a Member.
    *   *Note: While the specific university is not explicitly named in the header text, the document mentions the authors' IEEE membership status and provides an asterisk indicating Wanchun Liu is the corresponding author.*
[INFO] 2026-01-09 16:00:17.873 Query answer: Based on the provided document, the dataset statistics and experimental parameters are primarily detailed in **Table I** and the **Numerical Experiments** section (Section VI).

The "dataset" in this context refers to the training data generated by the DRL agent through interactions with a simulated environment (a remote state estimation system).

### **Dataset and Training Statistics (from Table I)**

| Hyperparameter / Statistic | Value |
| :--- | :--- |
| **Total Number of Episodes ($I$)** | 10,000 |
| **Pre-training Episodes ($I_1$)** | $10 \times N$ (e.g., 400 for a 40-device system) |
| **Time Horizon per Episode ($T$)** | 128 steps |
| **On-policy Batch Size ($B_1$)** | 128 |
| **Off-policy Batch Size ($B_2$)** | 128 |
| **Replay Buffer Size ($R$)** | 200 trajectories |
| **Sampled States for Score Scheme ($K$)** | 50 |
| **Tested AoI and Channel States ($\Xi$)** | 4 |
| **Past Trajectories for Avg. Score ($\bar{u}$)** | 50 |

### **System Scale and Environment Details (from Section VI-A and Table II)**
The experiments evaluate the algorithm across various system dimensions, which dictates the complexity of the state-action space:

*   **System Scales ($N$ devices, $M$ channels):**
    *   Small: (10, 5)
    *   Medium: (20, 10)
    *   Large: (30, 15)
    *   Very Large: (40, 20)
*   **State Space Dimensions:** $N + (N \times M)$. For the largest system (40, 20), the input dimension is $40 + 800 = 840$.
*   **Channel States:** Quantized into $\bar{g} = 5$ levels.
*   **Packet Drop Rates:** $\{0.2, 0.15, 0.1, 0.05, 0.01\}$.
*   **Evaluation Split:** Performance is verified using an empirical average MSE over **20,000-step simulations** across 16 different parameter settings (Para. 1-16).

### **Neural Network Architecture**
*   **Type:** Fully connected NNs with **three hidden layers**.
*   **Actor Output:** $2N$ (for SUDO-DRL and PPO).
*   **Critic Output:** 1 (estimated optimal V function).

The document notes that for the largest scale (40 devices, 20 channels), benchmark off-policy algorithms like DDPG fail to converge, whereas the SUDO-DRL dataset management (selective storage based on structural scores) allows for stable training.
[INFO] 2026-01-09 16:00:18.257 Query answer: Based on the provided document, the architecture and framework of the **SUDO-DRL** (Structure-guided Unified Dual On-off policy DRL) algorithm are primarily illustrated in **Figure 2** and **Figure 3**.

The architecture is a hybrid system that integrates **on-policy stability** (based on PPO) with **off-policy sample efficiency** (based on SAC), guided by **theoretical structural properties**.

### 1. Theoretical Structural Property Evaluation Framework (Fig. 2)
This component serves as the "guide" for the neural networks. It evaluates whether the NNs are adhering to the mathematical properties derived in the paper:
*   **Critic NN Evaluation:** Assesses the estimated state-value function $v(s)$ for:
    *   **Monotonicity:** Ensuring the value function increases with AoI and channel states (based on Lemma 1 and Theorem 1).
    *   **Convexity:** Ensuring the value function is asymptotically convex with respect to AoI states (based on Theorem 3).
*   **Actor NN Evaluation:** Assesses the sampled actions for:
    *   **Monotonicity:** Ensuring scheduling decisions are consistent with improved channel states (based on Theorem 4).
*   **Output Scores:** It generates three specific metrics: **CM** (Critic-Monotonicity), **CC** (Critic-Convexity), and **AM** (Actor-Monotonicity).

### 2. SUDO-DRL Main Architecture (Fig. 3)
The main framework is divided into three functional areas that interact to update the Actor and Critic NNs:

*   **Trajectory Sampling & Pre-training:**
    *   The **Actor NN** interacts with the **Wireless Environment** to generate experience trajectories.
    *   **Pre-training Phase:** Includes an "Additional Greedy Action Selection" block (based on Theorem 5) to provide a high-quality initial policy by prioritizing devices in the "mandatory scheduling set."

*   **On-Policy Part (Green Block):**
    *   Uses the current trajectory to calculate the **Advantage function ($A_t$)** and **Cost-to-go ($C_t$)**.
    *   **Structure-guided On-policy Loss ($L_{On}$):** Unlike standard PPO, this loss function includes a penalty term derived from the structural property evaluation metrics to force the Critic NN to respect monotonicity and convexity.

*   **Off-Policy Part (Blue Block):**
    *   **Structure-Guided Data Storage:** A decision gate checks if the current trajectory's structural scores (CM, CC, AM) meet specific constraints. If they do, the data is stored in the **Replay Buffer ($R$)**; otherwise, it is discarded.
    *   **Structural Priority-based Sampling:** Transitions are sampled from the buffer based on a priority indicator ($p$) that favors trajectories with higher structural alignment and recency.
    *   **Off-policy Loss ($L_{Off}$):** Calculates losses based on the sampled transitions to improve sample efficiency.

*   **Unified Update:**
    *   The final component is the **Unified Dual On-Off Policy Loss Function ($L_{SUDO}$)**, which sums the weighted on-policy and off-policy losses. This unified gradient is used to update the parameters of both the **Actor NN ($\varphi$)** and the **Critic NN ($\nu$)**.
[INFO] 2026-01-09 16:00:19.278 Query answer: Based on the provided document, the authors categorize existing approaches into three main groups and identify specific limitations for each:

### 1. Conventional Heuristic and Dynamic Programming Methods
*   **Heuristic Methods (e.g., Whittle’s Index):** While these are computationally efficient, the authors note that they **cannot guarantee optimality** in scheduling decisions.
*   **Conventional Dynamic Programming (e.g., Value and Policy Iteration):** These methods are described as **computationally infeasible** for modern goal-oriented systems. The high-dimensional state and action spaces (the "curse of dimensionality") make them impractical even for relatively small systems (e.g., a 10-device-5-channel system has over 30,000 possible actions).

### 2. Standard Deep Reinforcement Learning (DRL) Algorithms
The authors distinguish between off-policy and on-policy DRL, noting drawbacks in both:
*   **Off-Policy DRL (e.g., DQN, DDPG):** 
    *   **Instability and Bias:** These methods update the current policy using data from past policies, which introduces training instability and bias due to discrepancies between old and new behaviors.
    *   **Scalability Issues:** The paper explicitly states that benchmark off-policy algorithms **fail to converge** in large-scale scenarios (e.g., systems with 40 devices and 20 channels).
*   **On-Policy DRL (e.g., TRPO, PPO):**
    *   **Sample Inefficiency:** These methods discard data after each update to ensure stability, leading to poor data efficiency.
    *   **Suboptimal Exploration:** Discarding data can hinder the agent's ability to explore the environment thoroughly, often resulting in the policy getting stuck in **local minima**.
    *   **Performance Loss:** In large-scale systems, state-of-the-art on-policy methods exhibit "significant performance loss" compared to the proposed structure-guided approach.

### 3. Initial Structure-Enhanced DRL Studies
While some recent works have begun incorporating structural properties (like monotonicity or threshold structures), they suffer from the following:
*   **Limited Scope:** Most existing structure-aware algorithms rely exclusively on off-policy DRL (like DDPG). As a result, they inherit the instability of off-policy methods and are limited to small-scale systems (typically up to 20 sensors and 10 channels).
*   **Lack of Domain Insights:** Many general DRL applications use "brute-force optimization" without investigating the mathematical properties of the optimal policy, leading to less effective discovery of optimal solutions.
*   **Missing Theoretical Properties:** Prior to this paper, the authors claim that **asymptotic convexity** with respect to Age of Information (AoI) states had not been explored or proven in the context of transmission scheduling.

### Summary Table of Limitations
| Approach | Key Drawbacks |
| :--- | :--- |
| **Heuristics** | No guarantee of optimality. |
| **Dynamic Programming** | Computationally infeasible for large-scale systems. |
| **Off-Policy DRL** | Training instability, bias, and failure to converge in large systems. |
| **On-Policy DRL** | High sample inefficiency and tendency to hit local minima. |
| **Existing Structure-DRL** | Limited to small scales; lacks comprehensive structural insights (like convexity). |
[INFO] 2026-01-09 16:00:19.655 Query answer: The core model formulation for the goal-oriented transmission scheduling problem is a **Markov Decision Process (MDP)** designed to minimize the long-term expected sum of cost functions across multiple devices.

### 1. Objective Function
The primary goal is to find an optimal scheduling policy $\pi$ that minimizes the infinite-horizon expected discounted cost:
$$\min_{\pi} \lim_{T \to \infty} \mathbb{E}^{\pi} \left[ \sum_{t=1}^{T} \sum_{n=1}^{N} \gamma^{t} c_{n}(\delta_{n,t}) \right]$$
**Notation:**
*   $N$: Number of edge devices.
*   $\gamma \in (0,1)$: Discount factor.
*   $\delta_{n,t}$: Age of Information (AoI) for device $n$ at time $t$.
*   $c_{n}(\delta_{n,t})$: Application-specific cost function (non-decreasing with respect to AoI).

---

### 2. MDP Components
The system is modeled using the following state, action, and transition definitions:

*   **State ($\mathbf{s}_t$):** Comprises the AoI of all devices and the current channel states.
    $$\mathbf{s}_t \triangleq (\delta_t, \mathbf{G}_t) \in \mathcal{S}$$
    Where $\delta_t = \{\delta_{1,t}, \dots, \delta_{N,t}\}$ and $\mathbf{G}_t$ is an $N \times M$ channel state matrix.

*   **Action ($\mathbf{a}_t$):** The channel assignment for each device.
    $$\mathbf{a}_t = (a_{1,t}, \dots, a_{N,t}) \in \mathcal{A}$$
    Subject to constraints: $\sum_{n=1}^{N} \mathbb{1}(a_{n,t}=m) = 1$ (each channel assigned to one device) and $\sum_{m=1}^{M} \mathbb{1}(a_{n,t}=m) \leq 1$ (each device gets at most one channel).

*   **Transitions:** The probability of moving to the next state is:
    $$\mathrm{P}(\mathbf{s}^{+} | \mathbf{s}, \mathbf{a}) = \mathrm{P}(\delta^{+} | \delta, \mathbf{G}, \mathbf{a}) \mathrm{P}(\mathbf{G}^{+})$$
    The AoI transition for a specific device $n$ is:
    $$\mathrm{P}(\delta_{n}^{+} | \delta_{n}, \mathbf{g}_{n}, a_{n}) = \begin{cases} 1 - \psi_{n,m}, & \text{if } \delta_{n}^{+} = 1, a_{n} = m \\ \psi_{n,m}, & \text{if } \delta_{n}^{+} = \delta_{n} + 1, a_{n} = m \\ 1, & \text{if } \delta_{n}^{+} = \delta_{n} + 1, a_{n} = 0 \\ 0, & \text{otherwise} \end{cases}$$
    Where $\psi_{n,m}$ is the packet drop rate for device $n$ on channel $m$.

---

### 3. Bellman Optimality Equation
The solution is characterized by the **Optimal Action-Value Function (Q-function)**, which represents the expected cumulative discounted cost:
$$Q(\mathbf{s}_t, \mathbf{a}_t) = c(\mathbf{s}_t) + \gamma \sum_{\mathbf{s}_{t+1}} \mathrm{Pr}(\mathbf{s}_{t+1} | \mathbf{s}_t, \mathbf{a}_t) \min_{\mathbf{a}_{t+1} \in \mathcal{A}} Q(\mathbf{s}_{t+1}, \mathbf{a}_{t+1})$$
The optimal policy $\pi^*(\mathbf{s}_t)$ is then derived as:
$$\mathbf{a}_t^* = \arg \min_{\mathbf{a}_t \in \mathcal{A}} Q(\mathbf{s}_t, \mathbf{a}_t)$$
[INFO] 2026-01-09 16:00:20.563 Query answer: Based on the provided paper, here is a detailed description of the problem the authors aim to solve and the specific challenges involved:

### **The Core Problem**
The paper addresses the **Goal-oriented Transmission Scheduling** problem in a multi-device, multi-channel wireless communication system. Unlike traditional communications that focus on bit-level accuracy, this work prioritizes **application-driven objectives** (such as data freshness and system performance) by optimizing how $N$ edge devices share $M$ limited fading channels ($M < N$).

The primary goal is to find an optimal scheduling policy ($\pi$) that minimizes the long-term expected sum of cost functions across all devices. In the context of the provided example (a remote state estimation system), this means minimizing the **Mean Square Error (MSE)** of the estimated states, which is directly tied to the **Age of Information (AoI)**.

### **Specific Challenges**

The authors identify several critical challenges that make this problem difficult to solve using standard methods:

#### **1. High-Dimensional State and Action Spaces**
*   **State Space:** The system must track the AoI of every device and the channel states for every device-channel pair. This leads to a state space that grows exponentially with the number of devices.
*   **Action Space:** The scheduler must decide which device is assigned to which channel. For a system with $N$ devices and $M$ channels, the number of possible actions is $N! / (N-M)!$. For a relatively small 10-device-5-channel system, this already results in 30,240 possible actions, making conventional Markov Decision Process (MDP) solvers like value or policy iteration computationally infeasible.

#### **2. Limitations of Standard DRL Approaches**
*   **Off-Policy DRL (e.g., DQN, DDPG):** While sample-efficient because they reuse past data, these methods suffer from **training instability and bias**. Discrepancies between the current policy and the "old" data in the replay buffer can cause the training to diverge, especially in large-scale dynamic systems.
*   **On-Policy DRL (e.g., PPO, TRPO):** These are more stable but have **poor data efficiency**. They discard data after every update, which often leads to insufficient exploration and causes the agent to get stuck in **local minima**, resulting in suboptimal performance.

#### **3. Lack of Domain-Specific Guidance**
Most existing DRL applications use "brute-force" optimization without considering the underlying physics or mathematical structure of the communication problem. Without incorporating **structural properties** (like monotonicity or convexity), these algorithms struggle to find the theoretical optimal policy in complex environments.

#### **4. Scalability**
The paper notes that previous structure-enhanced DRL works were limited to small-scale systems (e.g., up to 20 sensors). Scaling to larger systems (e.g., 40 devices and 20 channels) causes benchmark off-policy algorithms to fail to converge and standard on-policy algorithms to suffer significant performance loss.

### **Summary of the Paper's Approach**
To overcome these, the authors:
1.  **Mathematically prove structural properties** of the optimal solution (monotonicity and asymptotic convexity of the value function).
2.  **Propose SUDO-DRL**, a hybrid algorithm that uses these properties to guide a "dual" on-policy and off-policy training process.
3.  **Introduce a Structural Property Evaluation Framework** to score and filter training data, ensuring the agent learns from "favorable" trajectories that align with theoretical optimality.
[INFO] 2026-01-09 16:00:21.571 Query answer: Based on the provided document, the research is motivated by several critical gaps in the field of goal-oriented communications and transmission scheduling. The unmet needs and the ways this work differentiates itself from prior research are detailed below:

### 1. The Gap: Limitations of Conventional Scheduling Methods
*   **Computational Infeasibility:** Traditional dynamic programming methods (like value or policy iteration) are computationally impossible to implement for large-scale systems due to the "curse of dimensionality" in high-dimensional state and action spaces.
*   **Suboptimality of Heuristics:** While heuristic methods (like Whittle’s Index) are efficient, they cannot guarantee optimality and often lead to significant performance loss in complex scenarios.

### 2. The Gap: Weaknesses in Existing DRL Approaches
*   **Instability vs. Inefficiency:** 
    *   **Off-policy DRL** (e.g., DQN, DDPG) is sample-efficient but suffers from training instability and bias because it updates the current policy using data from past, different policies.
    *   **On-policy DRL** (e.g., PPO, TRPO) is stable but has poor data efficiency because it discards data after each update, often failing to explore the state space sufficiently.
*   **Lack of Domain-Specific Insights:** Most existing works apply "brute-force" DRL without considering the underlying structural properties of the problem. This often results in agents getting stuck in local minima.

### 3. How This Research is Different from Prior Work
The authors differentiate their work through three primary innovations:

#### A. Advanced Theoretical Framework (The "Structure")
Unlike previous studies that only looked at basic monotonicity, this paper derives more complex structural properties:
*   **Asymptotic Convexity:** This is the first work in the literature to prove the asymptotic convexity of the optimal state value function with respect to Age of Information (AoI) states.
*   **Channel State Monotonicity:** It establishes that the optimal value function and policy are monotonic with respect to channel states, complementing earlier work that focused primarily on AoI.
*   **Greedy Structure:** It proves that for co-located devices, the optimal policy follows a "greedy" structure where devices with the highest AoI must be scheduled.

#### B. SUDO-DRL: A Hybrid "Dual" Approach
While prior "structure-enhanced" DRL works (like SE-DDPG or MRI-DDPG) relied exclusively on off-policy methods, this paper proposes **SUDO-DRL (Structure-guided Unified dual On-off policy DRL)**. 
*   **Unified Loss Function:** It combines the stability of on-policy training (PPO) with the efficiency of off-policy methods (SAC-like) into a single framework.
*   **Structure-Guided Replay Buffer:** Instead of a standard buffer, it uses a "Structure-Guided Data Storage Scheme" that only saves high-quality transitions that align with the proven theoretical properties (monotonicity and convexity).

#### C. Scalability to Large-Scale Systems
Prior structure-guided DRL algorithms were limited to small systems (e.g., 20 sensors and 10 channels). This research successfully addresses systems with **40 devices and 20 channels**—a scale where benchmark off-policy algorithms fail to converge and standard on-policy methods show significant performance degradation.

### Summary of Motivation
The research is driven by the need for a scheduling solution that is **simultaneously optimal, stable, sample-efficient, and scalable.** By "guiding" the learning process with mathematical proofs of how an optimal controller *should* behave (the structure), the authors bridge the gap between theoretical optimality and practical DRL implementation.
[INFO] 2026-01-09 16:00:23.932 Query answer: Based on the provided paper, the authors propose a novel deep reinforcement learning (DRL) framework called **SUDO-DRL (Structure-guided Unified Dual On-off policy DRL)**. This framework is designed to solve complex transmission scheduling problems in large-scale goal-oriented communication systems.

Below is a detailed overview of the proposed method, approach, and framework:

### 1. Theoretical Foundation (Structural Properties)
Before designing the algorithm, the paper derives several key structural properties of the optimal solution to the goal-oriented scheduling problem (which incorporates Age of Information (AoI) and channel states):
*   **Monotonicity of the Optimal V-function:** Proven with respect to both AoI states and channel states.
*   **Asymptotic Convexity:** The first result in literature to prove the asymptotic convexity of the state value function with respect to AoI states.
*   **Monotonicity of the Optimal Policy:** Established with respect to channel states.
*   **Asymptotic Greedy Structure:** For co-located devices, the optimal policy follows a greedy structure where devices with the highest AoI (above a certain threshold) must be scheduled.

### 2. The SUDO-DRL Framework
SUDO-DRL is a hybrid algorithm that combines the **stability of on-policy training** (based on Proximal Policy Optimization - PPO) with the **sample efficiency of off-policy methods** (based on Soft Actor-Critic - SAC).

#### A. Unified Dual Loss Function
The framework utilizes a unified loss function for both the Actor and Critic neural networks (NNs), balancing on-policy and off-policy components:
*   **Critic Loss:** Combines Temporal Difference (TD) error from current trajectories (on-policy) and sampled past data (off-policy), while adding **penalty terms** for any violations of the derived structural properties (monotonicity and convexity).
*   **Actor Loss:** Combines the PPO clipping loss (on-policy) with an entropy-regularized loss (off-policy) to improve exploration and stability.

#### B. Structural Property Evaluation Framework (See Fig. 2)
The paper introduces a framework to score trajectories based on how well they align with the theoretical properties:
*   **CM Score:** Critic-Monotonicity.
*   **CC Score:** Critic-Convexity.
*   **AM Score:** Actor-Monotonicity.
These scores are used to guide the learning process and ensure the NNs approximate the "true" optimal functions more accurately.

#### C. Structure-Guided Replay Buffer Management
Unlike standard off-policy DRL that stores all data, SUDO-DRL uses a **selective storage scheme**:
*   **Data Storage:** Only transitions from trajectories that meet or exceed average structural scores (CM, CC, AM) are stored in the replay buffer.
*   **Priority Sampling:** Transitions are sampled from the buffer based on a priority indicator derived from their structural scores and recency.

#### D. Structure-Guided Pre-training (See Fig. 3)
To avoid starting from scratch, the authors propose a pre-training stage. It uses the **Asymptotic Greedy Structure** (Theorem 5) to select initial actions. This provides a "good" starting policy, which the paper shows reduces convergence time by 40%.

### 3. Key Results and Scalability
The proposed framework is specifically designed to handle high-dimensional spaces. Numerical results demonstrate:
*   **Performance:** A 25% to 45% improvement in system performance (reducing Mean Square Error) compared to standard PPO.
*   **Scalability:** SUDO-DRL successfully manages systems with **40 devices and 20 channels**, a scale where traditional off-policy DRL (like DDPG) fails to converge and standard on-policy methods (PPO) show significant performance loss.
[INFO] 2026-01-09 16:00:25.614 Query answer: Based on the document provided, the main performance comparison is presented in **Table II**, which evaluates the **Empirical Average Cost** (specifically the average sum Mean Square Error) across 16 different parameter settings and 4 system scales.

### **Table II: Empirical Average Cost Comparison**

The table compares the proposed **SUDO-DRL** against four benchmarks: DDPG, SE-DDPG, MRI-DDPG, and PPO. (Note: "—" indicates the algorithm failed to converge at that scale).

| System Scale (N, M) | Para. | DDPG | SE-DDPG [21] | MRI-DDPG [22] | PPO | SUDO-DRL |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **(10, 5)** | 1 | 89.26 | 77.14 | 84.00 | 119.63 | **85.52** |
| | 2 | 98.87 | 87.30 | 90.28 | 123.01 | **95.82** |
| | 3 | — | 106.60 | 119.55 | 195.37 | **121.31** |
| | 4 | 83.12 | 78.21 | 80.88 | 120.93 | **80.68** |
| **(20, 10)** | 5 | — | 357.14 | 369.14 | 569.96 | **370.63** |
| | 6 | — | — | 445.87 | 584.37 | **426.29** |
| | 7 | — | 407.20 | 441.73 | 731.94 | **417.90** |
| | 8 | — | 290.72 | 307.94 | 376.16 | **308.91** |
| **(30, 15)** | 9 | — | — | — | 805.45 | **519.78** |
| | 10 | — | — | — | 739.97 | **575.34** |
| | 11 | — | — | — | 900.71 | **518.03** |
| | 12 | — | — | — | 901.42 | **551.97** |
| **(40, 20)** | 13 | — | — | — | 1057.05 | **719.45** |
| | 14 | — | — | — | 971.35 | **689.81** |
| | 15 | — | — | — | 1291.54 | **994.80** |
| | 16 | — | — | — | 1012.20 | **771.91** |

### **Key Observations from the Data:**
*   **Scalability:** Off-policy methods (DDPG, SE-DDPG, MRI-DDPG) fail to converge as the system scale increases to 30 devices or more. SUDO-DRL and PPO are the only methods that remain functional at the largest scale (40 devices, 20 channels).
*   **Performance Gain:** In large-scale scenarios (40, 20), SUDO-DRL consistently reduces the average MSE cost by **25% to 40%** compared to the standard PPO algorithm.
*   **Small-Scale Performance:** For the smallest scale (10, 5), SUDO-DRL performs comparably to advanced off-policy methods but is slightly outperformed by SE-DDPG, as off-policy methods are highly efficient at smaller dimensions.
*   **Convergence:** According to the text and Figure 4, SUDO-DRL achieves **40% faster convergence** than the version without pre-training and significantly outperforms PPO in stability and final cost.
[INFO] 2026-01-09 16:00:26.168 Query answer: Based on the provided document, there is **no specific "ablation study table"** that explicitly lists and compares the individual components of the SUDO-DRL algorithm (such as removing only the score scheme or only the pre-training).

However, the document provides a **performance comparison table** (Table II) and a **training performance graph** (Fig. 4) that function as a partial ablation study by comparing the full SUDO-DRL against its variants and benchmarks.

### 1. Performance Comparison (Table II)
This table compares the empirical average MSE cost across 16 different parameter settings and 4 system scales. It demonstrates how the structure-guided approach (SUDO-DRL) compares to standard on-policy (PPO) and off-policy (DDPG) methods.

| System Scale (N, M) | PPO (Standard On-Policy) | SUDO-DRL (Proposed) | Improvement |
| :--- | :--- | :--- | :--- |
| (10, 5) | 119.63 - 195.37 | **85.52 - 121.31** | ~30-40% |
| (20, 10) | 376.16 - 731.94 | **308.91 - 426.29** | ~20-40% |
| (30, 15) | 739.97 - 901.42 | **518.03 - 575.34** | ~35-40% |
| (40, 20) | 971.35 - 1291.54 | **689.81 - 994.80** | ~25-35% |

*Note: DDPG-based variants (SE-DDPG, MRI-DDPG) failed to converge for scales larger than (20, 10).*

### 2. Variant Comparison (Figure 4)
Figure 4 specifically compares three versions of the algorithm to show the impact of the proposed structural guidance and pre-training:

*   **PPO (Baseline):** Exhibits the highest average sum MSE (approx. 1000) and the slowest, most unstable convergence.
*   **SUDO-DRL (without pre-training):** Shows the impact of the **Unified Dual On-Off Policy** and **Structural Property Evaluation**. It achieves a significantly lower cost (approx. 700) than PPO but takes about 5000 episodes to stabilize.
*   **SUDO-DRL (Full):** Includes the **Structure-Guided Action Selection (Pre-training)**. This variant starts at a much lower cost (approx. 800) and converges 40% faster than the version without pre-training, ultimately reaching the lowest MSE (below 700).

### 3. Structural Score Results (Figures 5, 6, and 7)
The paper evaluates the "internal" effectiveness of the structural guidance by comparing scores between PPO and SUDO-DRL:
*   **Critic Monotonicity (CM):** SUDO-DRL reaches a perfect score of 100 almost immediately; PPO takes 1000 episodes.
*   **Critic Convexity (CC):** SUDO-DRL reaches 100 within 200 episodes; PPO never exceeds 80.
*   **Actor Monotonicity (AM):** SUDO-DRL reaches 100 by 2000 episodes; PPO plateaus below 75.

**Summary of Results:** The "ablation" logic in the text concludes that SUDO-DRL improves system performance by **25% to 45%** and reduces convergence time by **40%** compared to state-of-the-art methods.
[INFO] 2026-01-09 16:00:31.748 Query answer: Based on the provided document, the system design, model structure, and theoretical framework for goal-oriented transmission scheduling are detailed as follows:

### 1. System Model
The paper considers a wireless goal-oriented communication system consisting of:
*   **Edge Devices ($N$):** Cameras, sensors, or robots that generate local data.
*   **Channels ($M$):** Limited wireless subcarriers where $M < N$, requiring efficient scheduling.
*   **Remote Destination:** A base station or remote estimator that receives data to achieve specific application goals (e.g., remote state estimation).
*   **Communication Model:** Uses independent and identically distributed (i.i.d.) block fading channels. Channel states are quantized into $\bar{g}$ levels, each with a specific packet drop rate ($\psi$).
*   **Performance Metric:** The primary metric is the **Age of Information (AoI)**, which measures data freshness. The system aims to minimize a long-term discounted cost function $c_n(\delta_{n,t})$ based on AoI.

### 2. Theoretical Framework
The authors formulate the scheduling problem as a **Markov Decision Process (MDP)** and derive several key structural properties of the optimal solution:
*   **Monotonicity of the Value Function:** Proven with respect to both AoI states (fresher is better) and channel states (better channels reduce long-term cost).
*   **Asymptotic Convexity:** The first result in literature proving that the optimal state value function is asymptotically convex regarding AoI states.
*   **Optimal Policy Monotonicity:** If it is optimal to schedule a device on a specific channel, it remains optimal if that channel's quality improves.
*   **Greedy Structure:** For co-located devices, the optimal policy follows a greedy approach for devices with very high AoI (the "mandatory scheduling set").

### 3. SUDO-DRL Architecture
The **Structure-guided Unified Dual On-off policy DRL (SUDO-DRL)** is a hybrid algorithm designed to combine the stability of on-policy learning (PPO) with the efficiency of off-policy learning (SAC).

**Architecture Components (as shown in Fig. 3):**
*   **Trajectory Sampling:** Generates experience data. During pre-training, it uses a "Greedy Action Selection" based on Theorem 5.
*   **Structural Property Evaluation:** A framework (Fig. 2) that calculates scores for:
    *   **Critic-Monotonicity (CM)**
    *   **Critic-Convexity (CC)**
    *   **Actor-Monotonicity (AM)**
*   **On-Policy Part:** Uses a structure-guided loss function ($L_{On}$) that penalizes the Critic NN if it violates the proven monotonicity or convexity properties.
*   **Off-Policy Part:** Features a **Structure-Guided Data Storage Scheme**. It only stores transitions in the replay buffer if the trajectory's structural scores exceed the historical average. It also uses **Structural Priority-based Sampling**.
*   **Unified Loss Function:** Combines both parts: $L_{SUDO} = L_{On} + \beta L_{Off}$.

### 4. Key Tables and Data
*   **Table I (Training Hyperparameters):** Lists critical values such as a discount factor ($\gamma$) of 0.99, clipping parameter ($\epsilon$) of 0.2, and a unified policy weight ($\beta$) of 0.9.
*   **Table II (Empirical Average Cost):** Demonstrates that SUDO-DRL scales to large systems (40 devices, 20 channels) where traditional off-policy methods like DDPG fail to converge. It shows a performance improvement of 25% to 45% over the standard PPO algorithm.
*   **Performance Visuals:** Figures 5, 6, and 7 show that SUDO-DRL reaches near-perfect structural property scores (CM, CC, AM) much faster and more consistently than standard PPO, explaining its superior scheduling efficiency.
[INFO] 2026-01-09 16:00:32.774 Query answer: Based on the provided document, the proposed method is **SUDO-DRL (Structure-guided Unified Dual On-off policy DRL)**. It is a hybrid algorithm designed to solve large-scale goal-oriented transmission scheduling problems by combining the stability of on-policy learning with the sample efficiency of off-policy methods, all guided by derived theoretical structural properties.

The main components and steps of the method are as follows:

### 1. Theoretical Structural Property Derivation
The foundation of the method is the mathematical proof of four key properties of the optimal solution:
*   **Monotonicity of the V-function:** The optimal state-value function increases with both Age of Information (AoI) states (Lemma 1) and channel states (Theorem 1).
*   **Asymptotic Convexity:** The V-function is asymptotically convex with respect to AoI states (Theorem 3).
*   **Monotonicity of the Optimal Policy:** If a device is scheduled on a channel, it should remain scheduled if its channel quality improves (Theorem 4).
*   **Greedy Structure:** For co-located devices, the optimal policy follows a greedy structure for devices with very high AoI (Theorem 5).

### 2. Structural Property Evaluation Framework
This module (illustrated in Fig. 2) translates the theoretical proofs into quantifiable metrics to guide the Neural Networks (NNs):
*   **Critic-Monotonicity (CM) Score:** Measures how well the Critic NN respects the proven monotonicity.
*   **Critic-Convexity (CC) Score:** Measures the alignment of the Critic NN with the proven convexity.
*   **Actor-Monotonicity (AM) Score:** Evaluates if the Actor NN's scheduling decisions follow the channel-state monotonicity.

### 3. Unified Dual On-Off Policy Training
The algorithm maintains an Actor NN ($\varphi$) and a Critic NN ($\nu$) and updates them using a unified loss function that combines two parts:

*   **On-Policy Part (based on PPO):**
    *   **Experience Generation:** Generates trajectories using the current policy.
    *   **Structure-Guided Loss:** The standard PPO loss is augmented with penalty terms derived from the structural property evaluation (CM and CC scores) to ensure the Critic NN adheres to theoretical bounds.
*   **Off-Policy Part (based on SAC principles):**
    *   **Structure-Guided Data Storage:** Transitions are only stored in the Replay Buffer if the trajectory's structural scores (CM, CC, AM) exceed the average of past trajectories.
    *   **Priority-Based Sampling:** Transitions are sampled from the buffer based on a priority indicator ($p$) that combines the structural scores and the recency of the data.

### 4. Structure-Guided Pre-training
Before formal training begins, the method uses a **Structure-guided Action Selection** step. It leverages the "Greedy Structure" (Theorem 5) to select initial actions that prioritize devices in the "mandatory scheduling set" (those with the highest AoI). This provides a "good" initial policy, reducing convergence time by approximately 40%.

### 5. Implementation Steps (Algorithm 1)
1.  **Initialization:** Set environment parameters and random weights for NNs.
2.  **Trajectory Sampling:** Collect data; use greedy action selection if in the pre-training phase.
3.  **Structural Evaluation:** Calculate CM, CC, and AM scores for the current trajectory.
4.  **Buffer Management:** Store high-scoring trajectories in the replay buffer with priority indicators.
5.  **Loss Calculation:** Compute the unified loss ($L_{SUDO} = L_{On} + \beta L_{Off}$) for both the Actor and Critic.
6.  **Parameter Update:** Use the Adam optimizer to update NN weights based on the unified loss.
[INFO] 2026-01-09 16:00:34.005 Query answer: Based on the provided document, the key parameters, settings, and implementation details for the goal-oriented transmission scheduling system and the SUDO-DRL algorithm are detailed below:

### 1. System Model & Communication Parameters
*   **Network Scale:** The experiments evaluate various scales, ranging from small **(10 devices, 5 channels)** to large-scale scenarios with **40 devices and 20 channels**.
*   **Channel Model:** Independent and identically distributed (i.i.d.) block fading channels.
*   **Channel States ($\mathcal{G}$):** Quantized into **$\bar{g} = 5$ levels**.
*   **Packet Drop Rates:** Corresponding to the 5 channel levels, the rates are set at **0.2, 0.15, 0.1, 0.05, and 0.01**. These are derived from a Rayleigh distribution with a scale parameter between 0.5 and 2.
*   **Goal-Oriented Metric:** Age of Information (AoI) and specifically **Estimation Mean-Square Error (MSE)** for a remote state estimation system.
*   **LTI System Dynamics:** For each device $n$, the state dimension $r_n = 2$ and measurement dimension $e_n = 1$. System matrices $\mathbf{A}_n$ have spectral radii uniformly drawn from **(1, 1.3)**.

### 2. SUDO-DRL Algorithm Architecture
The algorithm is a hybrid "Unified Dual On-Off Policy" approach combining **PPO (on-policy)** and **SAC (off-policy)** elements.
*   **Neural Networks:** 
    *   **Actor NN:** Approximates the policy $\pi$; input dimension is $N + (N \times M)$. Output is $2N$ (for SUDO and PPO).
    *   **Critic NN:** Approximates the state-value function $v$; input dimension is $N + (N \times M)$. Output is 1.
    *   **Structure:** Both are fully connected NNs with **three hidden layers**.
*   **Loss Functions:** 
    *   **Critic Loss:** Combines Temporal Difference (TD) error with structural penalties for violations of **monotonicity** (w.r.t. AoI and channel) and **asymptotic convexity** (w.r.t. AoI).
    *   **Actor Loss:** Combines the PPO clipped objective with an off-policy SAC-based entropy term.

### 3. Training Hyperparameters (Table I)
*   **Learning Rates:** Critic = **0.001**, Actor = **0.0001** (with a decay rate of 0.001).
*   **Optimization:** **Adam Optimizer**.
*   **Discount Factor ($\gamma$):** 0.99.
*   **GAE Parameter ($\lambda$):** 0.99.
*   **PPO Clipping ($\epsilon$):** 0.2.
*   **Batch Sizes:** Both On-policy ($B_1$) and Off-policy ($B_2$) are set to **128**.
*   **Replay Buffer ($R$):** Size of **200** trajectories.
*   **Training Duration:** Total of **10,000 episodes**; Time horizon ($T$) per episode is **128**.

### 4. Structural Guidance Implementation
*   **Pre-training:** Uses a **Structure-Guided Action Selection** (based on Theorem 5) for the first $10 \times N$ episodes to provide a "good" initial policy.
*   **Score-Based Storage:** Trajectories are only stored in the off-policy replay buffer if they meet or exceed the average **Critic-Monotonicity (CM)**, **Critic-Convexity (CC)**, and **Actor-Monotonicity (AM)** scores of the past 50 trajectories.
*   **Priority Sampling:** Sampling from the buffer is weighted by a priority indicator ($p = CM + CC + AM$) and a recency decay rate ($\varrho = 0.95$).
*   **Sampling for Evaluation:** $K=50$ state-action pairs are sampled per trajectory, testing $\Xi=4$ AoI and channel states to calculate structural scores.

### 5. Performance Results
*   **Efficiency:** SUDO-DRL reduces convergence time by **40%** compared to versions without pre-training.
*   **Effectiveness:** Improves system performance (MSE reduction) by **25% to 45%** over the benchmark PPO.
*   **Scalability:** Successfully converges in a **40-device/20-channel** environment where standard off-policy DRL (DDPG) fails to converge.
[INFO] 2026-01-09 16:00:34.507 Query answer: Based on the provided document, the authors propose **SUDO-DRL (Structure-guided Unified Dual On-off policy DRL)**. This hybrid algorithm combines the stability of on-policy training (based on PPO) with the sample efficiency of off-policy methods (based on SAC), while being guided by the theoretical structural properties of the optimal scheduling policy.

The workflow is divided into three main phases: **Pre-training**, **Experience Generation**, and **Unified Parameter Updating**.

### 1. Pre-training Phase (Structure-Guided Initialization)
To avoid starting from scratch, the algorithm uses a "good" initial policy derived from the proven **asymptotic greedy structure** (Theorem 5).
*   **Procedure:** During the first $I_1$ episodes, the agent identifies a "mandatory scheduling set" (devices with the highest Age of Information (AoI) exceeding a certain threshold).
*   **Action Selection:** It prioritizes scheduling these devices regardless of channel state variations. This generates high-quality initial trajectories to populate the replay buffer and stabilize early training.

### 2. Experience Generation & Structural Evaluation
The algorithm generates data through a dual-path process:
*   **On-policy Trajectory Sampling:** The actor network generates a trajectory $\mathcal{T}_{\text{On}}$ of length $T$.
*   **Structural Property Evaluation Framework:** This is a key innovation. The sampled data is evaluated against three derived theoretical properties:
    1.  **Critic-Monotonicity (CM):** V-function should increase with AoI and channel states.
    2.  **Critic-Convexity (CC):** V-function should be asymptotically convex w.r.t. AoI.
    3.  **Actor-Monotonicity (AM):** If a device is scheduled to a channel, it should remain scheduled if that channel's quality improves.
*   **Score Calculation:** CM, CC, and AM scores are calculated. These scores determine if a trajectory is "good" enough to be stored in the off-policy replay buffer.

### 3. Unified Dual On-Off Policy Training
The core of the algorithm is the **Unified Loss Function**, which updates the Actor ($\varphi$) and Critic ($\nu$) networks by combining two sources:

#### A. On-policy Path (Stability)
*   Uses the current trajectory to calculate the Advantage function ($A_t$) and Cost-to-go ($C_t$).
*   **Critic Update:** Includes a standard Temporal Difference (TD) loss plus a **penalty term** for any violations of the structural properties (monotonicity and convexity) detected during evaluation.
*   **Actor Update:** Uses the standard PPO clipped objective function to ensure stable policy updates.

#### B. Off-policy Path (Efficiency)
*   **Structure-Guided Storage:** Only trajectories that meet or exceed the average CM, CC, and AM scores are stored in the Replay Buffer ($\mathcal{R}$).
*   **Priority-Based Sampling:** Transitions are sampled from the buffer based on a priority indicator ($p$) derived from their structural scores and recency.
*   **Loss Calculation:** Off-policy losses are calculated using an approximation of the Q-value (based on the V-function) to reduce complexity.

#### C. Parameter Update
The final gradients are computed using the unified loss:
*   $L_{\text{SUDO}} = L_{\text{On}} + \beta L_{\text{Off}}$
The weights $\beta_1, \beta_2$ balance the two approaches. The networks are then updated using the Adam optimizer.

### Summary of the Workflow (as per Fig. 3)
1.  **Sample Trajectory** (using greedy guidance if in pre-training).
2.  **Evaluate Structural Scores** (CM, CC, AM).
3.  **Filter & Store** high-score transitions into the **Replay Buffer**.
4.  **Sample Mini-batches** from both the current trajectory (On-policy) and the Replay Buffer (Off-policy).
5.  **Compute Unified Loss** (incorporating structural penalties in the on-policy critic loss).
6.  **Update Neural Networks** and repeat.
[INFO] 2026-01-09 16:00:35.013 Query answer: Based on the provided document, the evaluation of the proposed SUDO-DRL algorithm is conducted using the following datasets, benchmarks, and experimental setups:

### 1. Experimental Setup
The experiments are modeled on a **Remote State Estimation System** (as described in Example 1 of the paper).
*   **System Model:** $N$ edge devices (sensors) transmitting to a remote destination through $M$ channels ($M < N$).
*   **Dynamic Processes:** Each sensor measures a process modeled as a discrete-time linear time-invariant (LTI) system.
    *   **State/Measurement Dimensions:** Process state $r_n = 2$; measurement $c_n = 1$.
    *   **System Matrices ($A_n$):** Randomly generated with spectral radii uniformly drawn from $(1, 1.3)$.
*   **Communication Model:**
    *   **Channels:** Independent and identically distributed (i.i.d.) block fading channels.
    *   **Quantization:** Channel states are quantized into $\bar{g} = 5$ levels.
    *   **Packet Drop Rates:** Set to $0.2, 0.15, 0.1, 0.05,$ and $0.01$ (derived from a Rayleigh distribution with scale parameters between $0.5$ and $2$).
*   **Hardware/Software:** Intel Core i7 9700 CPU, 32GB RAM, and an NVIDIA RTX 3060Ti GPU.

### 2. Benchmarks
The paper compares SUDO-DRL against several state-of-the-art Deep Reinforcement Learning (DRL) algorithms:
*   **On-policy Benchmark:**
    *   **PPO (Proximal Policy Optimization):** The standard on-policy algorithm which SUDO-DRL builds upon.
*   **Off-policy Benchmarks:**
    *   **DDPG (Deep Deterministic Policy Gradient):** A fundamental off-policy actor-critic method.
    *   **SE-DDPG (Structure-Enhanced DDPG):** A previous state-of-the-art method that incorporates monotonicity properties.
    *   **MRI-DDPG (Monotonicity-Regularized DDPG):** A state-of-the-art approach for goal-oriented scheduling.

### 3. Evaluation Scenarios (System Scales)
The performance is tested across **16 different parameter settings** (Para. 1-16) and four primary system scales $(N, M)$:
*   **Small-scale:** (10 devices, 5 channels)
*   **Medium-scale:** (20 devices, 10 channels)
*   **Large-scale:** (30 devices, 15 channels) and **(40 devices, 20 channels)**.

### 4. Performance Metrics
The algorithms are evaluated using:
*   **Empirical Average Sum MSE Cost:** The primary goal-oriented metric (Mean Square Error of the remote estimation).
*   **Convergence Time/Speed:** Measured by the number of episodes required to reach a stable cost.
*   **Structural Property Scores:**
    *   **CM (Critic-Monotonicity):** Measures how well the critic NN follows proven monotonicity w.r.t. channel and AoI states.
    *   **CC (Critic-Convexity):** Measures adherence to the proven asymptotic convexity of the value function.
    *   **AM (Actor-Monotonicity):** Measures the monotonicity of the policy w.r.t. channel states.

### 5. Key Findings from Evaluation
*   **Scalability:** Off-policy benchmarks (DDPG, SE-DDPG, MRI-DDPG) failed to converge in systems larger than 20 devices.
*   **Efficiency:** SUDO-DRL improved system performance by **25% to 45%** and reduced convergence time by **40%** compared to the PPO benchmark.
*   **Structural Adherence:** As shown in Figures 5, 6, and 7, SUDO-DRL reaches near-perfect structural scores (100) much faster than PPO, which struggles particularly with convexity and actor monotonicity.
[INFO] 2026-01-09 16:00:37.032 Query answer: Based on the provided document, the key mathematical formulations, equations, and notations for the goal-oriented transmission scheduling problem are detailed below:

### 1. System Model and Communication Parameters
*   **Channel State:** $g_{n,m,t} \in \mathcal{G} \triangleq \{1,\ldots,\bar{g}\}$ represents the state between device $n$ and destination on channel $m$.
*   **Channel Distribution:** $\mathrm{P}(g_{n,m,t} = i) = q_{n,m}^i$, where $\sum_{i=1}^{\bar{g}} q_{n,m}^i = 1$.
*   **Channel Assignment Constraint (Eq. 3):**
    $$\sum_{n=1}^{N} \mathbb{1}(a_{n,t} = m) = 1, \quad \sum_{m=1}^{M} \mathbb{1}(a_{n,t} = m) \leq 1$$
    This ensures each channel is assigned to one device, and each device gets at most one channel.
*   **Age of Information (AoI) Dynamics (Eq. 4):**
    $$\delta_{n,t+1} = \begin{cases} 1, & \text{if successful reception} \\ \delta_{n,t} + 1, & \text{otherwise} \end{cases}$$

### 2. Goal-Oriented Cost Functions
*   **General Objective (Problem 1):** Minimize the infinite-horizon expected discounted cost:
    $$\min_{\pi} \lim_{T \to \infty} \mathbb{E}^\pi \left[ \sum_{t=1}^{T} \sum_{n=1}^{N} \gamma^t c_n(\delta_{n,t}) \right]$$
*   **Remote State Estimation MSE (Example 1):**
    $$c_n(\delta_{n,t}) \triangleq \operatorname{Tr}(\mathbf{P}_{n,t}) = \operatorname{Tr}\left( h_n^{\delta_{n,t}}(\bar{\mathbf{P}}_n) \right)$$
    Where $h_n(\mathbf{X}) = \mathbf{A}_n\mathbf{X}\mathbf{A}_n^\top + \mathbf{W}_n$.

### 3. MDP and Value Functions
*   **State Transition Probability (Eq. 6):**
    $$\mathrm{P}(\mathbf{s}^+ | \mathbf{s}, \mathbf{a}) = \mathrm{P}(\delta^+ | \delta, \mathbf{G}, \mathbf{a}) \mathrm{P}(\mathbf{G}^+)$$
*   **Bellman Optimality Equation (Eq. 7):**
    $$Q(\mathbf{s}_t, \mathbf{a}_t) = c(\mathbf{s}_t) + \gamma \sum_{\mathbf{s}_{t+1}} \mathrm{Pr}(\mathbf{s}_{t+1} | \mathbf{s}_t, \mathbf{a}_t) \min_{\mathbf{a}_{t+1} \in \mathcal{A}} Q(\mathbf{s}_{t+1}, \mathbf{a}_{t+1})$$
*   **Optimal State-Value Function (Eq. 9):** $v^*(\mathbf{s}_t) = \min_{\mathbf{a}_t \in \mathcal{A}} Q(\mathbf{s}_t, \mathbf{a}_t)$.

### 4. SUDO-DRL Structural Property Evaluation
The algorithm evaluates the Critic and Actor NNs using the following penalty metrics:
*   **Critic Monotonicity (AoI & Channel):**
    $$\hat{V}_{\mathrm{AoI}} = \max(0, v(\mathbf{s}; \boldsymbol{\nu}) - v(\hat{\mathbf{s}}_{(n)}; \boldsymbol{\nu}))$$
    $$\hat{V}_{\mathrm{Ch}} = \max(0, v(\mathbf{s}; \boldsymbol{\nu}) - v(\hat{\mathbf{s}}_{(n,m)}; \boldsymbol{\nu}))$$
*   **Critic Convexity (AoI):**
    $$\check{V}_{\mathrm{AoI}} = \max(0, 2v(\mathbf{s}; \boldsymbol{\nu}) - (v(\check{\mathbf{s}}_{(n)}; \boldsymbol{\nu}) + v(\hat{\mathbf{s}}_{(n)}; \boldsymbol{\nu})))$$
*   **Actor Monotonicity (Channel):**
    $$\acute{\Lambda}_{\mathrm{Ch},n} = \mathbb{1}(a_n \neq 0 \text{ and } a_{\mathrm{Ch},n} \neq a_n)$$

### 5. Unified Loss Functions
SUDO-DRL combines on-policy (On) and off-policy (Off) losses:
*   **Critic Loss (Eq. 22 & 31):**
    $$L_{\mathrm{SUDO}}(\boldsymbol{\nu}) = L_{\mathrm{On}}(\boldsymbol{\nu}) + \beta_1 L_{\mathrm{Off}}(\boldsymbol{\nu})$$
    $$L_{\mathrm{On}}(\boldsymbol{\nu}) = \frac{1}{B_1} \sum_{l=1}^{B_1} \mathrm{TD}_l^2 + \frac{1}{K\Xi} \sum_{k=1}^{K} \sum_{\xi=1}^{\Xi} (\hat{V}_{\mathrm{AoI},k,\xi} + \hat{V}_{\mathrm{Ch},k,\xi} + \check{V}_{\mathrm{AoI},k,\xi})$$
*   **Actor Loss (Eq. 23 & 38):**
    $$L_{\mathrm{SUDO}}(\varphi) = L_{\mathrm{On}}(\varphi) + \beta_2 L_{\mathrm{Off}}(\varphi)$$
    $$L_{\mathrm{Off}}(\varphi) = \frac{1}{B_2} \sum_{b=1}^{B_2} \left[ \varpi \log(\pi(\tilde{\mathbf{a}}_b | \mathbf{s}_b; \varphi)) + (c_b + \gamma v(\tilde{\mathbf{s}}_{b+1}; \boldsymbol{\nu})) \right]$$

### 6. Off-Policy Replay Buffer Sampling
*   **Priority Indicator (Eq. 35):** $p_u = \mathrm{CM}_u + \mathrm{CC}_u + \mathrm{AM}_u$ (Sum of Critic Monotonicity, Critic Convexity, and Actor Monotonicity scores).
*   **Sampling Probability (Eq. 36):**
    $$P_b \triangleq \frac{p_b \cdot \varrho^b}{\sum_{b=1}^R (p_b \cdot \varrho^b)}$$
    Where $\varrho \in (0,1]$ is the decay rate for recency.
[INFO] 2026-01-09 16:00:37.387 Query answer: Based on the provided document, the objective function, optimization goal, and theoretical derivations for the goal-oriented transmission scheduling problem are detailed as follows:

### 1. Objective Function
The problem is formulated as an infinite-horizon Markov Decision Process (MDP). The objective function is the **expected discounted sum of cost functions** across all $N$ devices:
$$\min_{\pi} \lim_{T \to \infty} \mathbb{E}^{\pi} \left[ \sum_{t=1}^{T} \sum_{n=1}^{N} \gamma^{t} c_{n}(\delta_{n,t}) \right]$$
*   **$c_n(\delta_{n,t})$**: An application-specific cost function (e.g., Mean Square Error in remote estimation) that is non-decreasing with respect to the Age of Information (AoI).
*   **$\delta_{n,t}$**: The AoI state of device $n$ at time $t$.
*   **$\gamma$**: The discount factor $\in (0,1)$.

### 2. Optimization Goal
The primary goal is to determine an optimal dynamic scheduling policy $\pi^*$ that minimizes the long-term system cost by deciding which devices should transmit over $M$ available channels ($M < N$) at each time step $t$, given the current AoI states ($\delta_t$) and channel states ($\mathbf{G}_t$).

### 3. Theoretical Derivations (Structural Properties)
The authors derive several key properties of the optimal Value function ($v^*$) and Policy ($\pi^*$) to guide the DRL agent:

*   **Monotonicity of $v^*$ w.r.t. Channel States (Theorem 1):** The authors prove that the optimal state-value function is monotonically decreasing with respect to channel quality (higher channel states/better quality lead to lower long-term costs).
*   **Asymptotic Convexity of $v^*$ w.r.t. AoI (Theorem 3 & Proposition 1):** They establish that $v^*$ is asymptotically convex relative to AoI states. This means that as information becomes increasingly stale, the "penalty" or cost to the system grows at an increasing rate.
*   **Monotonicity of Optimal Policy w.r.t. Channel States (Theorem 4):** If it is optimal to schedule a device on a specific channel, it remains optimal if that channel's quality improves, provided all other variables remain constant.
*   **Asymptotic Greedy Structure (Theorem 5):** For co-located devices (identical channels), the optimal policy follows a "greedy" structure where it is mandatory to schedule devices with the highest AoI (those in the "mandatory scheduling set").

### 4. SUDO-DRL Optimization Approach
The paper uses these derivations to create the **SUDO-DRL** algorithm, which optimizes via a **Unified Dual On-Off Policy Loss Function**:
*   **On-Policy Component:** Uses a PPO-based loss but adds a **structural penalty term** (Equation 31) that punishes the Critic NN if its outputs violate the proven monotonicity or convexity properties.
*   **Off-Policy Component:** Employs a **Structure-Guided Data Storage Scheme**. Only trajectories that align with the theoretical properties (high CM, CC, and AM scores) are stored in the replay buffer.
*   **Pre-training:** Uses the **Greedy Structure (Theorem 5)** to select actions during an initial phase, providing a "good" starting policy rather than training from scratch.
[INFO] 2026-01-09 16:00:38.605 Query answer: Based on the document provided, the main results are presented in **Table II: Empirical Average Cost of the SUDO-DRL Algorithm and the Benchmarks**. The table compares the performance of the proposed **SUDO-DRL** against four state-of-the-art methods across 16 different parameter settings and four system scales.

The key findings from this table are:

### 1. Superior Scalability
The table demonstrates that SUDO-DRL is significantly more robust as system complexity increases:
*   **Small Scale (10 devices, 5 channels):** All algorithms (DDPG, SE-DDPG, MRI-DDPG, PPO, and SUDO-DRL) are generally able to converge.
*   **Medium Scale (20 devices, 10 channels):** Standard DDPG fails to converge (indicated by "—"), while structure-enhanced versions (SE-DDPG, MRI-DDPG) still function.
*   **Large Scale (30+ devices, 15-20 channels):** All off-policy benchmarks (DDPG, SE-DDPG, and MRI-DDPG) **fail to converge**. Only the on-policy PPO and the proposed SUDO-DRL are capable of handling these high-dimensional spaces.

### 2. Significant Performance Gains
SUDO-DRL consistently achieves the lowest (best) empirical average MSE cost in large-scale scenarios:
*   **Compared to PPO:** In the largest tested scenario (40 devices, 20 channels), SUDO-DRL reduces the average cost by approximately **25% to 40%** compared to the standard PPO algorithm.
*   **Consistency:** Across all 16 parameter settings, SUDO-DRL (highlighted in bold in the table) consistently outperforms the on-policy benchmark (PPO).

### 3. Comparison with Specialized Off-Policy Methods
*   In small-scale systems (10, 5), the table shows that SUDO-DRL is comparable to, though sometimes slightly behind, specialized off-policy methods like SE-DDPG. The authors note this is because off-policy methods are highly efficient in smaller, less complex environments.
*   However, as the system grows, those specialized methods become non-functional, whereas SUDO-DRL maintains high performance.

### 4. Summary of Numerical Improvements
The text accompanying the table (and the abstract) synthesizes these results, noting that SUDO-DRL:
*   Improves system performance by **up to 45%**.
*   Reduces convergence time by **40%** (as supported by the training curves in Fig. 4).
*   Successfully manages systems with up to **40 devices and 20 channels**, a scale where previous structure-guided off-policy DRL methods were limited to roughly 20 sensors.
[INFO] 2026-01-09 16:00:39.642 Query answer: Based on the provided document, the performance of the transmission scheduling system and the SUDO-DRL algorithm is measured using several distinct categories of metrics:

### 1. Primary System Performance Metric
*   **Sum of Cost Functions (MSE):** The central objective is to minimize the infinite-horizon expected sum of cost functions across all $N$ devices. 
*   **Remote State Estimation (Example 1):** In the specific case of remote state estimation, the cost function $c_n(\delta_{n,t})$ is defined as the **Estimation Mean-Square Error (MSE)**. This measures the error covariance of the remote estimate, which is a function of the **Age of Information (AoI)**.
*   **Age of Information (AoI):** Defined as the time elapsed since the last successful packet reception ($\delta_{n,t}$). It serves as a proxy for information freshness and directly influences the cost function.

### 2. DRL Training and Efficiency Metrics
The paper evaluates the effectiveness of the SUDO-DRL algorithm using the following:
*   **Average Sum MSE Cost:** Used to plot learning curves (Fig. 4) to compare the final performance of different algorithms.
*   **Convergence Time:** Measured by the number of episodes required to reach a stable, minimum cost. SUDO-DRL is noted to reduce convergence time by approximately 40%.
*   **Scalability:** The ability of the algorithm to converge in large-scale systems (e.g., 40 devices and 20 channels), where traditional off-policy methods like DDPG fail.

### 3. Structural Property Evaluation Scores
A novel framework (illustrated in **Fig. 2**) is used to measure how well the neural networks adhere to theoretically proven optimal properties. These are expressed as scores from 0 to 100:
*   **Critic-Monotonicity (CM) Score:** Measures if the Critic NN respects the property that the value function should increase as AoI or channel states worsen (based on Lemma 1 and Theorem 1).
*   **Critic-Convexity (CC) Score:** Measures if the Critic NN follows the proven asymptotic convexity of the value function with respect to AoI states (Theorem 3).
*   **Actor-Monotonicity (AM) Score:** Measures if the Actor NN follows the property that if a device is scheduled on a channel, it should remain scheduled if that channel's quality improves (Theorem 4).

### 4. Algorithmic Stability and Efficiency
*   **Sample Efficiency:** The ability to learn effectively from fewer data points by combining on-policy stability with off-policy data reuse (via the replay buffer).
*   **Training Stability:** Measured by the lack of bias and fluctuations during the policy update process, primarily attributed to the unified dual on-off policy approach.

### 5. Numerical Comparison Criteria
In **Table II**, the algorithms are compared across 16 different parameter settings ("Para. 1-16") based on:
*   **Empirical Average Cost:** The average MSE calculated over 20,000-step simulations after training is complete.
*   **Success Rate:** Whether an algorithm can successfully converge ("—" indicates failure to converge) for a given system scale $(N, M)$.
[INFO] 2026-01-09 16:00:43.245 Query answer: Based on the provided document, the proposed **SUDO-DRL (Structure-guided Unified Dual On-off policy DRL)** method significantly outperforms baseline methods in terms of performance, scalability, and training efficiency.

### 1. Performance and Scalability Comparison
The paper compares SUDO-DRL against several state-of-the-art algorithms: **PPO** (on-policy benchmark), **DDPG** (off-policy benchmark), **SE-DDPG**, and **MRI-DDPG** (structure-guided off-policy benchmarks).

*   **System Performance:** SUDO-DRL improves system performance (measured by Mean Square Error/MSE) by **25% to 45%** compared to the PPO benchmark.
*   **Scalability:** SUDO-DRL demonstrates superior scalability. It effectively handles large-scale systems with up to **40 devices and 20 channels**. 
    *   **Off-policy baselines (DDPG, SE-DDPG, MRI-DDPG)** fail to converge entirely in these large-scale setups.
    *   **On-policy baseline (PPO)** converges but exhibits significant performance loss (higher MSE) compared to SUDO-DRL.
*   **Small-Scale Systems:** In smaller systems (e.g., 10 devices, 5 channels), SUDO-DRL achieves performance comparable to advanced off-policy methods like SE-DDPG, though it is noted to be slightly worse because off-policy methods are highly specialized for small-scale optimality.

### 2. Training Efficiency
*   **Convergence Time:** SUDO-DRL reduces convergence time by approximately **40%** compared to versions without its specific structure-guided enhancements.
*   **Stability:** By combining on-policy stability with off-policy sample efficiency, it avoids the training instability and bias often found in pure off-policy methods (like DDPG) while overcoming the data inefficiency of pure on-policy methods (like PPO).

### 3. Structural Property Alignment
The paper uses "Structure Scores" (CM, CC, and AM) to show how well the NNs adhere to theoretical optimal properties (monotonicity and convexity). The comparison in **Figures 5, 6, and 7** shows:
*   **Critic Monotonicity (CM):** SUDO-DRL reaches a perfect score (100) almost immediately, whereas PPO takes 1,000 episodes.
*   **Critic Convexity (CC):** SUDO-DRL reaches a perfect score within 200 episodes, while PPO never exceeds a score of 80.
*   **Actor Monotonicity (AM):** SUDO-DRL reaches a perfect score by 2,000 episodes, while PPO plateaus below 75.

### Summary Table (Based on Table II)
| System Scale (N, M) | DDPG | SE-DDPG / MRI-DDPG | PPO | SUDO-DRL |
| :--- | :--- | :--- | :--- | :--- |
| **Small (10, 5)** | Works | **Best Performance** | Poor Performance | High Performance |
| **Medium (20, 10)** | Fails | Works | Poor Performance | **Best Performance** |
| **Large (40, 20)** | Fails | **Fails** | Works (High Cost) | **Best Performance (Low Cost)** |

### Key Advantages of the Proposed Method
1.  **Hybrid Approach:** It uses a unified loss function that integrates the stability of PPO with the sample efficiency of SAC (Soft Actor-Critic).
2.  **Structure-Guided Storage:** It selectively stores "high-quality" data in the replay buffer only if the trajectory aligns with proven structural properties (monotonicity/convexity).
3.  **Pre-training:** It uses a greedy structure (Theorem 5) to initialize the policy, leading to much faster initial learning.
[INFO] 2026-01-09 16:00:43.613 Query answer: Based on the numerical experiments detailed in Section VI and the corresponding figures, the proposed **SUDO-DRL** method achieves the following performance results:

### **1. Overall System Performance (MSE Cost)**
*   **Reduction in Cost:** SUDO-DRL improves system performance by **25% to 45%** compared to state-of-the-art methods (specifically the benchmark on-policy PPO algorithm).
*   **Large-Scale Scenarios:** In a system with **40 devices and 20 channels** (the largest scale tested), SUDO-DRL reduced the average sum MSE cost by approximately **35%** compared to PPO (as shown in Fig. 4).
*   **Empirical Average Cost (Table II):** Across 16 different parameter settings, SUDO-DRL consistently outperformed PPO. For example:
    *   **Scale (30, 15):** Achieved costs as low as **518.03** compared to PPO's **900.71**.
    *   **Scale (40, 20):** Achieved costs as low as **689.81** compared to PPO's **971.35**.

### **2. Training Efficiency and Convergence**
*   **Convergence Speed:** The method reduces convergence time by approximately **40%** compared to state-of-the-art methods.
*   **Impact of Pre-training:** The use of the structure-guided pre-training stage allowed the algorithm to converge in significantly fewer episodes—achieving over **40% faster convergence** than SUDO-DRL without pre-training (Fig. 4).

### **3. Scalability**
*   **Robustness:** SUDO-DRL successfully handles large-scale systems (up to **40 devices and 20 channels**). 
*   **Benchmark Failure:** In these large-scale setups, off-policy benchmarks like **DDPG, SE-DDPG, and MRI-DDPG failed to converge**, while the standard on-policy PPO exhibited significant performance loss.

### **4. Structural Property Alignment (Scores)**
The method ensures that the neural networks adhere to theoretical optimal properties, measured on a scale of 0–100:
*   **Critic Monotonicity (CM):** Achieved a full score of **100** very quickly (Fig. 5).
*   **Critic Convexity (CC):** Guaranteed a full score of **100** after approximately **200 episodes**, whereas the PPO benchmark remained below 80 (Fig. 6).
*   **Actor Monotonicity (AM):** Reached a score of **100** after **2000 episodes**, while PPO failed to exceed 75 (Fig. 7).
[INFO] 2026-01-09 16:00:45.683 Query answer: Based on the provided document, the authors conduct a comprehensive evaluation of the **SUDO-DRL** algorithm, which serves as a form of structural ablation and sensitivity analysis by comparing it against standard on-policy and off-policy benchmarks.

The analysis focuses on three primary areas: the contribution of the **pre-training stage**, the impact of **system scale (scalability)**, and the effectiveness of the **structural property scores**.

### 1. Ablation of the Pre-training Stage
The authors specifically analyze the impact of the "Structure-Guided Action Selection" used during pre-training (based on the greedy structure derived in Theorem 5).
*   **The Study:** They compare SUDO-DRL with a version of itself that excludes the pre-training phase (labeled "SUDO-DRL without pre-training" in Fig. 4).
*   **Findings:** 
    *   **Convergence Speed:** The pre-training stage reduces convergence time by approximately **40%**.
    *   **Final Performance:** The version with pre-training achieves a lower average cost (MSE), suggesting that the structural guidance helps the agent avoid local minima and find a better initialization point for formal training.

### 2. Sensitivity to System Scale (Scalability Analysis)
The study tests the algorithms across 16 different parameter settings and four system scales: (10 devices, 5 channels), (20, 10), (30, 15), and (40, 20).
*   **The Study:** Comparing SUDO-DRL against off-policy (DDPG, SE-DDPG, MRI-DDPG) and on-policy (PPO) benchmarks as the state/action space dimensions increase.
*   **Findings:**
    *   **Off-policy Failure:** Standard off-policy methods (DDPG) only work at the smallest scale. State-of-the-art variants (SE-DDPG, MRI-DDPG) fail to converge once the system reaches 30 devices.
    *   **On-policy Performance Loss:** While the on-policy benchmark (PPO) converges in large systems, it exhibits significant performance loss.
    *   **SUDO-DRL Superiority:** SUDO-DRL is the only algorithm that remains both stable and efficient at the largest scale (40 devices/20 channels), improving system performance by **25% to 45%** over PPO (Table II).

### 3. Structural Property Score Evaluation
The authors evaluate how well the NNs adhere to the derived theoretical properties (Monotonicity and Convexity) during the training process.
*   **The Study:** They track three metrics: **Critic-Monotonicity (CM)**, **Critic-Convexity (CC)**, and **Actor-Monotonicity (AM)** scores (Figs. 5, 6, and 7).
*   **Findings:**
    *   **Critic Monotonicity:** SUDO-DRL reaches a perfect score (100) almost immediately, whereas PPO takes 1,000 episodes.
    *   **Critic Convexity:** SUDO-DRL guarantees a full score after 200 episodes, while PPO never rises above 80.
    *   **Actor Monotonicity:** SUDO-DRL reaches a full score after 2,000 episodes, while PPO plateaus below 75.
*   **Conclusion:** This analysis proves that standard DRL (PPO) struggles to learn the underlying mathematical structure of the optimal policy (especially convexity), which explains the performance gap.

### Summary of Findings
The analysis demonstrates that **SUDO-DRL** successfully bridges the gap between on-policy stability and off-policy efficiency. By enforcing structural properties (monotonicity and convexity) through its unified loss function and using a structure-guided replay buffer, it achieves **faster convergence, better scalability, and higher accuracy** in goal-oriented communication tasks.
[INFO] 2026-01-09 16:00:48.691 Query answer: Based on the provided document, this work introduces several novel theoretical and algorithmic contributions to the field of goal-oriented transmission scheduling. The key innovations are detailed below:

### 1. New Theoretical Structural Properties
While previous works (including the authors' own earlier research) identified basic monotonicity, this paper significantly advances the theoretical framework by proving three new properties of the optimal solution:
*   **Asymptotic Convexity of the Value Function:** This is the first result in the literature to explore and prove the convexity of the optimal state-value function ($v^*$) with respect to Age of Information (AoI) states. The authors prove this for two-device systems (Theorem 2) and establish asymptotic convexity for multi-device-multi-channel systems (Theorem 3).
*   **Monotonicity w.r.t. Channel States:** The authors prove that the optimal $v^*$ function is monotonically decreasing with respect to channel states (Theorem 1), complementing existing knowledge of monotonicity regarding AoI.
*   **Asymptotic Greedy Structure:** The paper proves that for co-located devices (identical channel conditions), the optimal policy follows a "greedy" structure where devices in a "mandatory scheduling set" (those with the highest AoI) must be scheduled (Theorem 5).

### 2. SUDO-DRL: A Hybrid "Dual" Architecture
Most existing methods use either **on-policy** DRL (stable but sample-inefficient, like PPO) or **off-policy** DRL (efficient but unstable in large scales, like DQN/DDPG). This work proposes the **Structure-guided Unified Dual On-off policy DRL (SUDO-DRL)**, which is novel in its hybrid approach:
*   **Unified Loss Function:** It combines the stability of on-policy training with the sample efficiency of off-policy methods through a single unified loss function ($L_{SUDO} = L_{On} + \beta L_{Off}$).
*   **Structural Property Evaluation Framework:** As shown in **Fig. 2**, the algorithm introduces a framework that calculates "scores" for Critic-Monotonicity (CM), Critic-Convexity (CC), and Actor-Monotonicity (AM). These scores are used to penalize the NNs when they violate the proven theoretical properties.

### 3. Novel Replay Buffer Management
Unlike standard off-policy methods that store all experiences, SUDO-DRL uses a **Structure-Guided Data Storage Scheme**:
*   **Selective Storage:** It only stores transitions in the replay buffer if the trajectory's structural scores (CM, CC, AM) meet specific constraints (Equation 34).
*   **Priority-Based Sampling:** It uses a priority indicator ($p$) based on these structural scores to sample "high-quality" data that aligns with theoretical optimality, rather than just sampling based on temporal recency or TD-error.

### 4. Structure-Guided Pre-training
The algorithm introduces a specific pre-training stage (Algorithm 1, Step 6) that uses the **Greedy Structure** derived in Theorem 5. This allows the agent to find a "good" initial policy quickly, rather than starting from a random state. This was shown to reduce convergence time by 40% (**Fig. 4**).

### 5. Superior Scalability
A major practical novelty is the demonstrated scalability. Existing off-policy methods (DDPG, SE-DDPG) failed to converge in large-scale scenarios (e.g., 40 devices, 20 channels). SUDO-DRL not only converges in these environments but outperforms the standard on-policy benchmark (PPO) by **25% to 45%** in system performance (**Table II**).
[INFO] 2026-01-09 16:00:48.901 Query answer: Based on the provided document, the analysis and discussion of results are centered on the theoretical derivation of structural properties and the empirical validation of the proposed **SUDO-DRL** algorithm.

### 1. Theoretical Analysis of Structural Properties
The authors provide a rigorous mathematical analysis of the optimal scheduling policy, which serves as the foundation for their DRL algorithm. Key findings include:
*   **Monotonicity of the Value Function:** The authors prove that the optimal state-value function ($v^*$) is monotonically increasing with respect to both **Age of Information (AoI) states** (Lemma 1) and **channel states** (Theorem 1). This implies that system performance degrades as data becomes older or channel conditions worsen.
*   **Asymptotic Convexity:** For the first time in transmission scheduling literature, the authors prove the **asymptotic convexity** of the value function with respect to AoI states (Theorem 3). This suggests that the "cost" of outdated information increases at an accelerating rate as AoI grows.
*   **Optimal Policy Structure:** Theorem 4 establishes the monotonicity of the optimal policy regarding channel states, while Theorem 5 identifies an **asymptotic greedy structure** for co-located devices. This means that in certain conditions, the optimal policy aligns with a "greedy" approach that prioritizes devices with the highest immediate cost.

### 2. Case Study: Remote State Estimation System
The paper uses a **Remote State Estimation System** (Example 1) as its primary case study to evaluate the goal-oriented framework.
*   **Setup:** The system involves $N$ sensors measuring linear time-invariant (LTI) processes and sending estimates to a remote estimator.
*   **Metric:** The performance goal is to minimize the **Mean Square Error (MSE)** of the remote estimates.
*   **Linkage:** The authors prove in Lemma 2 that the MSE cost function in this system is asymptotically convex, justifying the use of convexity-based guidance in their DRL model.

### 3. Discussion of Numerical Results
The results are discussed through comparisons with state-of-the-art algorithms (PPO, DDPG, SE-DDPG, and MRI-DDPG) across 16 different parameter settings:

*   **Performance and Scalability:**
    *   SUDO-DRL outperforms the benchmark PPO by **25% to 45%** in terms of reducing the average sum MSE.
    *   **Scalability:** SUDO-DRL successfully handles large-scale systems (up to **40 devices and 20 channels**). In contrast, off-policy benchmarks like DDPG fail to converge at this scale, and PPO exhibits significant performance loss (Fig. 4 and Table II).
*   **Convergence Efficiency:**
    *   The inclusion of a **pre-training stage** (guided by the greedy structure in Theorem 5) reduces convergence time by approximately **40%** (Fig. 4).
*   **Structural Property Scores (Figures 5, 6, and 7):**
    *   The authors use a "score" system (CM, CC, and AM) to track how well the NNs adhere to the proven theoretical properties during training.
    *   **Critic Monotonicity (CM):** SUDO-DRL reaches a perfect score almost immediately, whereas PPO takes 1,000 episodes.
    *   **Critic Convexity (CC) and Actor Monotonicity (AM):** SUDO-DRL maintains near-perfect scores, while PPO struggles significantly (staying below 80 for CC and 75 for AM). This confirms that SUDO-DRL’s superior performance is directly linked to its ability to enforce these theoretical structures.

### 4. Summary of SUDO-DRL Innovation
The discussion highlights that the algorithm's success stems from its **Unified Dual Approach**:
1.  **On-policy:** Provides training stability via a structure-guided loss function.
2.  **Off-policy:** Enhances sample efficiency by using a **Structure-Guided Data Storage Scheme**, which only keeps high-quality transitions in the replay buffer based on their structural property scores.
[INFO] 2026-01-09 16:00:48.991 Query answer: Based on the provided document, the main contributions of this work are detailed in the introduction and summarized in the conclusion. They can be categorized into three primary areas:

### 1. Theoretical Derivation of Structural Properties
The authors establish several key structural properties of the optimal solution for goal-oriented transmission scheduling (which considers both Age of Information (AoI) and channel states):
*   **Monotonicity of the Optimal V Function:** They prove that the optimal state-value function is monotonically increasing with respect to **channel states** (Theorem 1), complementing previous work that showed monotonicity regarding AoI states.
*   **Asymptotic Convexity:** They provide the first result in the literature to prove the **asymptotic convexity** of the state-value function with respect to AoI states in transmission scheduling problems (Theorem 3 and Proposition 1).
*   **Monotonicity of the Optimal Policy:** They derive the monotonicity of the optimal scheduling policy with respect to channel states (Theorem 4).
*   **Greedy Structure:** They establish an **asymptotic greedy structure** for the optimal policy in systems with co-located devices (Theorem 5), suggesting that devices with the highest AoI (above a certain threshold) must be scheduled.

### 2. Development of the SUDO-DRL Algorithm
The paper proposes the **Structure-guided Unified Dual On-off policy DRL (SUDO-DRL)**, a hybrid algorithm designed to solve large-scale MDPs:
*   **Hybrid Approach:** It combines the **stability of on-policy training** (based on PPO) with the **sample efficiency of off-policy methods** (based on SAC) through a unified loss function.
*   **Structural Property Evaluation Framework:** As shown in **Fig. 2**, the algorithm calculates "scores" for critic-monotonicity (CM), critic-convexity (CC), and actor-monotonicity (AM).
*   **Structure-Guided Loss and Buffer Management:** 
    *   The **on-policy loss function** incorporates penalties for violating the derived structural properties.
    *   The **off-policy replay buffer** uses a selective storage scheme (storing only high-quality data that aligns with structural properties) and a priority-based sampling method.
*   **Pre-training Stage:** It utilizes the "greedy structure" derived in the theory to guide action selection during an initial pre-training phase to find a better starting policy.

### 3. Numerical Validation and Scalability
The authors demonstrate the efficacy of SUDO-DRL through extensive experiments (as seen in **Table II** and **Figs. 4-7**):
*   **Performance Gains:** SUDO-DRL improves system performance (reduces MSE cost) by **25% to 45%** compared to state-of-the-art methods like PPO.
*   **Efficiency:** It reduces convergence time by approximately **40%**.
*   **Scalability:** The algorithm successfully handles large-scale systems (up to **40 devices and 20 channels**). This is a significant contribution because benchmark off-policy algorithms (like DDPG) fail to converge at this scale, and standard on-policy benchmarks (like PPO) exhibit significant performance loss.
[INFO] 2026-01-09 16:00:49.099 Query answer: Based on the provided document, the paper acknowledges several limitations and suggests specific future research directions to build upon the SUDO-DRL framework.

### **Acknowledged Limitations**

The paper identifies limitations in both existing methodologies and the specific scope of the current study:

*   **Computational Infeasibility of Conventional Methods:** The authors note that traditional dynamic programming methods (like value and policy iteration) are computationally infeasible for large-scale systems due to high-dimensional state and action spaces.
*   **Suboptimality of Heuristics:** Heuristic methods, while efficient, cannot guarantee optimality in goal-oriented scheduling.
*   **DRL Algorithm Trade-offs:**
    *   **Off-policy DRL (e.g., DQN, DDPG):** While sample-efficient, these methods suffer from training instability and bias. The paper specifically notes that state-of-the-art off-policy algorithms (like SE-DDPG) fail to converge in large-scale setups (e.g., 40 devices and 20 channels).
    *   **On-policy DRL (e.g., PPO):** These methods are stable but exhibit poor data efficiency and insufficient exploration, often getting stuck in local minima.
*   **Theoretical Constraints:**
    *   **Convexity Proofs:** While the authors prove asymptotic convexity for multi-device systems, they acknowledge that proving absolute convexity for general multi-device-multi-channel systems is extremely challenging due to the increased dimensionality of state and action spaces.
    *   **Channel State Convexity:** The authors explicitly state they did not derive convexity for channel states because it is "neither meaningful nor necessary," as the cost function fundamentally depends on AoI rather than channel quality.
    *   **Policy Monotonicity:** The paper mentions that general results for policy monotonicity in terms of AoI have not yet been derived for multi-device systems (only for special cases like two-device-single-channel).
*   **Scenario Specificity:** Some theoretical results (like the greedy structure of the optimal policy) were only derived for the special case of "co-located devices" with identical channel states.

### **Suggested Future Directions**

The paper outlines several avenues for future research to enhance goal-oriented communication systems:

*   **Expansion of Theoretical Framework:** The authors suggest exploring additional structural properties of the optimal solution to further refine the guidance provided to DRL algorithms.
*   **Comprehensive Resource Allocation:** Future work aims to extend the SUDO-DRL algorithm beyond simple transmission scheduling to include:
    *   **Power Allocation:** Optimizing the energy used for transmissions alongside scheduling.
    *   **Advanced Multiple Access Schemes:** Integrating techniques like Non-Orthogonal Multiple Access (NOMA) into the scheduling framework.
*   **Broader Application Goals:** While this paper focuses heavily on Age of Information (AoI) and remote state estimation, future directions involve applying these structure-guided methods to other goal-oriented metrics and application-specific objectives in 6G networks.
*   **Scalability Enhancements:** Continuing to improve the scalability of these algorithms to handle even larger and more complex network environments where current benchmarks exhibit performance loss.
[INFO] 2026-01-09 16:00:49.102   Completed 26 queries
[INFO] 2026-01-09 16:00:49.117   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_rag.json
[INFO] 2026-01-09 16:00:49.119 
[INFO] 2026-01-09 16:00:49.119 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:00:49.119 STAGE: SUMMARY
[INFO] 2026-01-09 16:00:49.121 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:00:50.555 Extracting content from indexed documents (paper)...
[INFO] 2026-01-09 16:00:50.556   Extracting paper metadata from 1 markdown file(s)...
[INFO] 2026-01-09 16:00:52.925   Paper metadata extracted successfully
[INFO] 2026-01-09 16:01:10.543   Summary: 10426 chars
[INFO] 2026-01-09 16:01:10.544 Extracting tables and figures...
[INFO] 2026-01-09 16:01:10.552   Tables: 2, Figures: 0
[INFO] 2026-01-09 16:01:10.570   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\checkpoint_summary.json
[INFO] 2026-01-09 16:01:10.573 
[INFO] 2026-01-09 16:01:10.574 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:01:10.574 STAGE: PLAN
[INFO] 2026-01-09 16:01:10.574 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:01:10.588 Planning content...
[INFO] 2026-01-09 16:01:12.485 Calling LLM with text only (no images)
[INFO] 2026-01-09 16:01:12.485 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 16:01:26.019 LLM returned 5699 characters
[INFO] 2026-01-09 16:01:26.019 ================================================================================
[INFO] 2026-01-09 16:01:26.020 LLM Response for Content Planning:
[INFO] 2026-01-09 16:01:26.020 --------------------------------------------------------------------------------
[INFO] 2026-01-09 16:01:26.020 ```json
{
  "sections": [
    {
      "id": "poster_header",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "Authors: Jiazheng Chen, Wanchun Liu*. This research addresses the critical challenge of efficient transmission scheduling in large-scale goal-oriented communication systems, specifically focusing on remote state estimation where Age of Information (AoI) directly impacts system performance.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_motivation",
      "title": "Motivation and Problem Statement",
      "content": "The study focuses on a multi-device multi-channel wireless system where \\( N \\) devices share \\( M \\) fading channels (\\( M < N \\)). The core objective is to find an optimal scheduling policy \\( \\pi \\) that minimizes the long-term expected total cost, such as the Mean Square Error (MSE) in remote state estimation. Conventional methods face a 'curse of dimensionality'; for instance, a 10-device 5-channel system generates 30,240 possible actions. Existing DRL approaches suffer from a trade-off: Off-policy algorithms (DQN, DDPG) are sample-efficient but unstable in large-scale systems (failing at 40 devices), while On-policy algorithms (PPO) are stable but sample-inefficient and prone to local optima. There is a significant research gap in integrating the mathematical structural properties of communication problems, such as the monotonicity and asymptotic convexity of the value function, into the DRL training process.",
      "tables": [],
      "figures": []
    },
    {
      "id": "poster_methodology",
      "title": "SUDO-DRL Framework and Methodology",
      "content": "SUDO-DRL (Structure-guided Unified Dual On-off policy DRL) bridges the gap between stability and efficiency. It derives theoretical properties of the optimal policy—Monotonicity (V-function increases with AoI), Asymptotic Convexity (V-function
[INFO] 2026-01-09 16:01:26.022 ... (truncated, total length: 5699 chars)
[INFO] 2026-01-09 16:01:26.023 ================================================================================
[INFO] 2026-01-09 16:01:26.024 Found JSON in code block
[INFO] 2026-01-09 16:01:26.028   Generated 5 sections:
[INFO] 2026-01-09 16:01:26.028     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (content)
[INFO] 2026-01-09 16:01:26.029     [2] Motivation and Problem Statement (content)
[INFO] 2026-01-09 16:01:26.029     [3] SUDO-DRL Framework and Methodology (content)
[INFO] 2026-01-09 16:01:26.029     [4] Experimental Results and Performance Evaluation (content)
[INFO] 2026-01-09 16:01:26.029     [5] Key Contributions and Conclusion (content)
[INFO] 2026-01-09 16:01:26.034   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\checkpoint_plan.json
[INFO] 2026-01-09 16:01:26.037 
[INFO] 2026-01-09 16:01:26.037 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:01:26.037 STAGE: GENERATE
[INFO] 2026-01-09 16:01:26.038 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:01:26.045 Generating images...
[INFO] 2026-01-09 16:01:28.114 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 16:01:28.115   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 16:01:28.115   Prompt length: 5188 chars
[INFO] 2026-01-09 16:02:14.454 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 16:02:15.197 Image generation successful (Doubao, URL, 1375523 bytes)
[INFO] 2026-01-09 16:02:15.205   [1/1] Saved: poster.png
[INFO] 2026-01-09 16:02:15.205   Generated 1 images
[INFO] 2026-01-09 16:02:15.205 
[INFO] 2026-01-09 16:02:15.206 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_160126
[INFO] 2026-01-09 16:02:15.209 
[INFO] 2026-01-09 16:02:15.210 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:02:15.210 SUMMARY
[INFO] 2026-01-09 16:02:15.211 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:02:15.211   [✓] rag: completed
[INFO] 2026-01-09 16:02:15.212   [✓] summary: completed
[INFO] 2026-01-09 16:02:15.212   [✓] plan: completed
[INFO] 2026-01-09 16:02:15.212   [✓] generate: completed
[INFO] 2026-01-09 16:02:15.213 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 16:02:15.213 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 16:02:15.217 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始上传文件...
[INFO] 2026-01-09 16:02:15.217 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始上传文件...
[INFO] 2026-01-09 16:02:15.539 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/result_id/poster.png
[INFO] 2026-01-09 16:02:15.541 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/result_id/poster.png
[INFO] 2026-01-09 16:02:15.541 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/result_id/poster.png
[INFO] 2026-01-09 16:02:15.546 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始更新用户数据...
[INFO] 2026-01-09 16:02:15.546 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始更新用户数据...
[INFO] 2026-01-09 16:02:15.551 只更新当前任务: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, update_system=False
[INFO] 2026-01-09 16:02:15.551 只更新当前任务: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, update_system=False
[INFO] 2026-01-09 16:02:15.552 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 用户数据更新完成
[INFO] 2026-01-09 16:02:15.552 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 用户数据更新完成
[INFO] 2026-01-09 16:02:15.558 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始更新系统数据...
[INFO] 2026-01-09 16:02:15.558 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 开始更新系统数据...
[INFO] 2026-01-09 16:02:15.559 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 16:02:15.559 [1b9a609e-fce7-49de-a3fc-cb828a2de68b] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 16:02:15.563 任务执行完成: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, status=success
[INFO] 2026-01-09 16:02:15.563 任务执行完成: 1b9a609e-fce7-49de-a3fc-cb828a2de68b, status=success
[INFO] 2026-01-09 16:02:15.565 任务成功: 1b9a609e-fce7-49de-a3fc-cb828a2de68b
[INFO] 2026-01-09 16:02:15.565 任务成功: 1b9a609e-fce7-49de-a3fc-cb828a2de68b
[INFO] 2026-01-09 16:02:17.604 运行中任务数减少: 0
[INFO] 2026-01-09 16:02:17.607 已清理临时文件: 1b9a609e-fce7-49de-a3fc-cb828a2de68b
[INFO] 2026-01-09 16:02:17.607 已清理临时文件: 1b9a609e-fce7-49de-a3fc-cb828a2de68b
[INFO] 2026-01-09 16:02:17.612 Task celery_app.tasks.generate_slides_task[1b9a609e-fce7-49de-a3fc-cb828a2de68b] succeeded in 146.40599999995902s: {'result_id': '1b9a609e-fce7-49de-a3fc-cb828a2de68b', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/result_id/poster.png', 'images': None, 'error_message': None}
[WARNING] 2026-01-09 16:12:15.404 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 16:12:17.431 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 16:12:17.433 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 16:12:19.488 mingle: searching for neighbors
[INFO] 2026-01-09 16:12:26.644 mingle: all alone
[INFO] 2026-01-09 16:12:36.894 celery@DESKTOP-4FIVBBU ready.
[WARNING] 2026-01-09 16:48:34.267 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 16:48:36.312 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 16:48:36.317 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 16:48:40.450 mingle: searching for neighbors
[INFO] 2026-01-09 16:48:47.591 mingle: all alone
[INFO] 2026-01-09 16:48:55.763 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 16:48:55.772 Task celery_app.tasks.generate_slides_task[af1545ed-106c-4ee9-89e6-2ee4d091dc52] received
[INFO] 2026-01-09 16:48:57.898 开始执行任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 16:48:57.898 开始执行任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 16:49:00.365 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 16:49:00.441 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始参数校验...
[INFO] 2026-01-09 16:49:00.441 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始参数校验...
[INFO] 2026-01-09 16:49:00.447 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 任务状态已更新为 running
[INFO] 2026-01-09 16:49:00.447 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 任务状态已更新为 running
[INFO] 2026-01-09 16:49:00.466 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始下载文件...
[INFO] 2026-01-09 16:49:00.466 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始下载文件...
[INFO] 2026-01-09 16:49:00.467 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:49:00.467 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:49:00.469 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 16:49:00.471 MinIO客户端初始化成功
[INFO] 2026-01-09 16:49:00.751 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 16:49:00.752 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 16:49:00.752 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\af1545ed-106c-4ee9-89e6-2ee4d091dc52\2501.11921.md
[INFO] 2026-01-09 16:49:00.757 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始调用生成管道...
[INFO] 2026-01-09 16:49:00.757 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始调用生成管道...
[INFO] 2026-01-09 16:49:00.760 Starting pipeline from stage: generate
[INFO] 2026-01-09 16:49:00.761 Session ID: 3b730e50-08a6-4a84-a05d-0a364fd4e5a4
[INFO] 2026-01-09 16:49:00.762 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 16:49:00.762 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense
[INFO] 2026-01-09 16:49:00.770 
[INFO] 2026-01-09 16:49:00.771 Starting from stage: generate
[INFO] 2026-01-09 16:49:00.771 
[INFO] 2026-01-09 16:49:00.771 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:49:00.772 STAGE: GENERATE
[INFO] 2026-01-09 16:49:00.772 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:49:03.867 Generating images...
[INFO] 2026-01-09 16:49:06.081 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 16:49:06.082   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 16:49:06.082   Prompt length: 5188 chars
[INFO] 2026-01-09 16:49:56.573 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 16:49:57.328 Image generation successful (Doubao, URL, 1461482 bytes)
[INFO] 2026-01-09 16:49:57.332   [1/1] Saved: poster.png
[INFO] 2026-01-09 16:49:57.333   Generated 1 images
[INFO] 2026-01-09 16:49:57.335 
[INFO] 2026-01-09 16:49:57.335 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\poster_academic_dense\20260109_164903
[INFO] 2026-01-09 16:49:57.338 
[INFO] 2026-01-09 16:49:57.338 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:49:57.338 SUMMARY
[INFO] 2026-01-09 16:49:57.339 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:49:57.339   [✓] rag: completed
[INFO] 2026-01-09 16:49:57.339   [✓] summary: completed
[INFO] 2026-01-09 16:49:57.340   [✓] plan: completed
[INFO] 2026-01-09 16:49:57.340   [✓] generate: completed
[INFO] 2026-01-09 16:49:57.341 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 16:49:57.341 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 生成完成，输出文件: 1 个
[INFO] 2026-01-09 16:49:57.343 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始上传文件...
[INFO] 2026-01-09 16:49:57.343 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始上传文件...
[INFO] 2026-01-09 16:49:57.800 文件已上传: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/af1545ed-106c-4ee9-89e6-2ee4d091dc52/poster.png
[INFO] 2026-01-09 16:49:57.802 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/af1545ed-106c-4ee9-89e6-2ee4d091dc52/poster.png
[INFO] 2026-01-09 16:49:57.802 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 文件上传完成: kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/af1545ed-106c-4ee9-89e6-2ee4d091dc52/poster.png
[INFO] 2026-01-09 16:49:57.808 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始更新用户数据...
[INFO] 2026-01-09 16:49:57.808 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始更新用户数据...
[INFO] 2026-01-09 16:49:57.820 只更新当前任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 16:49:57.820 只更新当前任务: af1545ed-106c-4ee9-89e6-2ee4d091dc52, update_system=False
[INFO] 2026-01-09 16:49:57.823 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 用户数据更新完成
[INFO] 2026-01-09 16:49:57.823 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 用户数据更新完成
[INFO] 2026-01-09 16:49:57.830 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始更新系统数据...
[INFO] 2026-01-09 16:49:57.830 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 开始更新系统数据...
[INFO] 2026-01-09 16:49:57.831 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 16:49:57.831 [af1545ed-106c-4ee9-89e6-2ee4d091dc52] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 16:49:57.833 任务执行完成: af1545ed-106c-4ee9-89e6-2ee4d091dc52, status=success
[INFO] 2026-01-09 16:49:57.833 任务执行完成: af1545ed-106c-4ee9-89e6-2ee4d091dc52, status=success
[INFO] 2026-01-09 16:49:57.835 任务成功: af1545ed-106c-4ee9-89e6-2ee4d091dc52
[INFO] 2026-01-09 16:49:57.835 任务成功: af1545ed-106c-4ee9-89e6-2ee4d091dc52
[INFO] 2026-01-09 16:49:59.902 运行中任务数减少: 0
[INFO] 2026-01-09 16:49:59.903 已清理临时文件: af1545ed-106c-4ee9-89e6-2ee4d091dc52
[INFO] 2026-01-09 16:49:59.903 已清理临时文件: af1545ed-106c-4ee9-89e6-2ee4d091dc52
[INFO] 2026-01-09 16:49:59.945 Task celery_app.tasks.generate_slides_task[af1545ed-106c-4ee9-89e6-2ee4d091dc52] succeeded in 64.15599999995902s: {'result_id': 'af1545ed-106c-4ee9-89e6-2ee4d091dc52', 'status': 'success', 'file_path': 'kb-poster-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/af1545ed-106c-4ee9-89e6-2ee4d091dc52/poster.png', 'images': None, 'error_message': None}
[INFO] 2026-01-09 16:50:23.527 Task celery_app.tasks.generate_slides_task[0fd12e3d-1934-485a-9aa7-b646f577efe3] received
[INFO] 2026-01-09 16:50:23.531 开始执行任务: 0fd12e3d-1934-485a-9aa7-b646f577efe3, update_system=False
[INFO] 2026-01-09 16:50:23.531 开始执行任务: 0fd12e3d-1934-485a-9aa7-b646f577efe3, update_system=False
[INFO] 2026-01-09 16:50:23.600 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始参数校验...
[INFO] 2026-01-09 16:50:23.600 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始参数校验...
[INFO] 2026-01-09 16:50:23.603 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 任务状态已更新为 running
[INFO] 2026-01-09 16:50:23.603 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 任务状态已更新为 running
[INFO] 2026-01-09 16:50:23.605 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始下载文件...
[INFO] 2026-01-09 16:50:23.605 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始下载文件...
[INFO] 2026-01-09 16:50:23.608 [0fd12e3d-1934-485a-9aa7-b646f577efe3] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:50:23.608 [0fd12e3d-1934-485a-9aa7-b646f577efe3] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:50:23.793 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\0fd12e3d-1934-485a-9aa7-b646f577efe3\2501.11921.md
[INFO] 2026-01-09 16:50:23.794 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\0fd12e3d-1934-485a-9aa7-b646f577efe3\2501.11921.md
[INFO] 2026-01-09 16:50:23.794 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\0fd12e3d-1934-485a-9aa7-b646f577efe3\2501.11921.md
[INFO] 2026-01-09 16:50:23.798 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始调用生成管道...
[INFO] 2026-01-09 16:50:23.798 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 开始调用生成管道...
[INFO] 2026-01-09 16:50:23.803 Starting pipeline from stage: plan
[INFO] 2026-01-09 16:50:23.803 Session ID: 17edb80c-2b9e-46e0-8972-5c1ce02d2ce0
[INFO] 2026-01-09 16:50:23.804 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 16:50:23.805 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\slides_academic_dense
[INFO] 2026-01-09 16:50:23.807 
[INFO] 2026-01-09 16:50:23.808 Starting from stage: plan
[INFO] 2026-01-09 16:50:23.809 
[INFO] 2026-01-09 16:50:23.809 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:50:23.811 STAGE: PLAN
[INFO] 2026-01-09 16:50:23.811 ────────────────────────────────────────────────────────────
[ERROR] 2026-01-09 16:50:23.819 Stage failed: 'dense' is not a valid SlidesLength
[INFO] 2026-01-09 16:50:23.820 
[INFO] 2026-01-09 16:50:23.821 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:50:23.821 SUMMARY
[INFO] 2026-01-09 16:50:23.822 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:50:23.822   [○] rag: pending
[INFO] 2026-01-09 16:50:23.823   [○] summary: pending
[INFO] 2026-01-09 16:50:23.823   [✗] plan: failed
[INFO] 2026-01-09 16:50:23.823   [○] generate: pending
[ERROR] 2026-01-09 16:50:23.824 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 参数校验失败: 管道返回的 output_files 为空
[ERROR] 2026-01-09 16:50:23.824 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 参数校验失败: 管道返回的 output_files 为空
[INFO] 2026-01-09 16:50:23.829 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 用户任务已标记为失败: 管道返回的 output_files 为空
[INFO] 2026-01-09 16:50:23.829 [0fd12e3d-1934-485a-9aa7-b646f577efe3] 用户任务已标记为失败: 管道返回的 output_files 为空
[ERROR] 2026-01-09 16:50:23.849 智能体执行失败: 管道返回的 output_files 为空
Traceback (most recent call last):
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 295, in call_api_node
    raise Exception("管道返回的 output_files 为空")
Exception: 管道返回的 output_files 为空

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 605, in run
    final_state = await self.app.ainvoke(initial_state)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\main.py", line 3158, in ainvoke
    async for chunk in self.astream(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\main.py", line 2971, in astream
    async for _ in runner.atick(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\_runner.py", line 304, in atick
    await arun_with_retry(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\_retry.py", line 137, in arun_with_retry
    return await task.proc.ainvoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\_internal\_runnable.py", line 705, in ainvoke
    input = await asyncio.create_task(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\_internal\_runnable.py", line 473, in ainvoke
    ret = await self.afunc(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 328, in call_api_node
    raise Exception(error_msg)
Exception: 管道返回的 output_files 为空
During task with name 'call_api' and id 'c3c839d3-8740-e828-4975-e599428a451b'

[ERROR] 2026-01-09 16:50:23.849 智能体执行失败: 管道返回的 output_files 为空
Traceback (most recent call last):
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 295, in call_api_node
    raise Exception("管道返回的 output_files 为空")
Exception: 管道返回的 output_files 为空

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 605, in run
    final_state = await self.app.ainvoke(initial_state)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\main.py", line 3158, in ainvoke
    async for chunk in self.astream(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\main.py", line 2971, in astream
    async for _ in runner.atick(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\_runner.py", line 304, in atick
    await arun_with_retry(
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\pregel\_retry.py", line 137, in arun_with_retry
    return await task.proc.ainvoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\_internal\_runnable.py", line 705, in ainvoke
    input = await asyncio.create_task(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Anaconda\envs\slide-svc\Lib\site-packages\langgraph\_internal\_runnable.py", line 473, in ainvoke
    ret = await self.afunc(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\agents\slides_agent.py", line 328, in call_api_node
    raise Exception(error_msg)
Exception: 管道返回的 output_files 为空
During task with name 'call_api' and id 'c3c839d3-8740-e828-4975-e599428a451b'

[INFO] 2026-01-09 16:50:23.852 任务执行完成: 0fd12e3d-1934-485a-9aa7-b646f577efe3, status=failed
[INFO] 2026-01-09 16:50:23.852 任务执行完成: 0fd12e3d-1934-485a-9aa7-b646f577efe3, status=failed
[ERROR] 2026-01-09 16:50:23.854 任务失败: 0fd12e3d-1934-485a-9aa7-b646f577efe3, 错误: 管道返回的 output_files 为空
[ERROR] 2026-01-09 16:50:23.854 任务失败: 0fd12e3d-1934-485a-9aa7-b646f577efe3, 错误: 管道返回的 output_files 为空
[ERROR] 2026-01-09 16:50:23.855 任务执行异常: 0fd12e3d-1934-485a-9aa7-b646f577efe3, 错误: 管道返回的 output_files 为空
[ERROR] 2026-01-09 16:50:23.855 任务执行异常: 0fd12e3d-1934-485a-9aa7-b646f577efe3, 错误: 管道返回的 output_files 为空
[INFO] 2026-01-09 16:50:23.860 运行中任务数减少: 0
[INFO] 2026-01-09 16:50:23.862 已清理临时文件: 0fd12e3d-1934-485a-9aa7-b646f577efe3
[INFO] 2026-01-09 16:50:23.862 已清理临时文件: 0fd12e3d-1934-485a-9aa7-b646f577efe3
[ERROR] 2026-01-09 16:50:23.871 Task celery_app.tasks.generate_slides_task[0fd12e3d-1934-485a-9aa7-b646f577efe3] raised unexpected: Exception('管道返回的 output_files 为空')
[INFO] 2026-01-09 16:55:42.849 Task celery_app.tasks.generate_slides_task[14c105ee-1e08-4a22-9f5b-247ec628cf29] received
[INFO] 2026-01-09 16:55:42.852 开始执行任务: 14c105ee-1e08-4a22-9f5b-247ec628cf29, update_system=False
[INFO] 2026-01-09 16:55:42.852 开始执行任务: 14c105ee-1e08-4a22-9f5b-247ec628cf29, update_system=False
[INFO] 2026-01-09 16:55:42.917 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始参数校验...
[INFO] 2026-01-09 16:55:42.917 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始参数校验...
[INFO] 2026-01-09 16:55:42.923 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 任务状态已更新为 running
[INFO] 2026-01-09 16:55:42.923 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 任务状态已更新为 running
[INFO] 2026-01-09 16:55:42.930 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始下载文件...
[INFO] 2026-01-09 16:55:42.930 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始下载文件...
[INFO] 2026-01-09 16:55:42.931 [14c105ee-1e08-4a22-9f5b-247ec628cf29] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:55:42.931 [14c105ee-1e08-4a22-9f5b-247ec628cf29] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 16:55:43.112 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\14c105ee-1e08-4a22-9f5b-247ec628cf29\2501.11921.md
[INFO] 2026-01-09 16:55:43.113 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\14c105ee-1e08-4a22-9f5b-247ec628cf29\2501.11921.md
[INFO] 2026-01-09 16:55:43.113 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\14c105ee-1e08-4a22-9f5b-247ec628cf29\2501.11921.md
[INFO] 2026-01-09 16:55:43.115 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始调用生成管道...
[INFO] 2026-01-09 16:55:43.115 [14c105ee-1e08-4a22-9f5b-247ec628cf29] 开始调用生成管道...
[INFO] 2026-01-09 16:55:43.117 Starting pipeline from stage: plan
[INFO] 2026-01-09 16:55:43.117 Session ID: 8979b4d9-5784-48f1-9ef1-f27863914cfb
[INFO] 2026-01-09 16:55:43.117 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 16:55:43.118 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\slides_academic_dense
[INFO] 2026-01-09 16:55:43.122 
[INFO] 2026-01-09 16:55:43.122 Starting from stage: plan
[INFO] 2026-01-09 16:56:10.822 
[INFO] 2026-01-09 16:56:10.823 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 16:56:10.823 STAGE: PLAN
[INFO] 2026-01-09 16:56:10.823 ────────────────────────────────────────────────────────────
[WARNING] 2026-01-09 17:01:52.866 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 17:01:54.911 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 17:01:54.914 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 17:01:56.939 mingle: searching for neighbors
[INFO] 2026-01-09 17:02:04.081 mingle: all alone
[INFO] 2026-01-09 17:02:14.325 celery@DESKTOP-4FIVBBU ready.
[INFO] 2026-01-09 17:02:47.816 Task celery_app.tasks.generate_slides_task[360bdae4-2950-4351-af88-9bdc07c69b49] received
[INFO] 2026-01-09 17:02:49.920 开始执行任务: 360bdae4-2950-4351-af88-9bdc07c69b49, update_system=False
[INFO] 2026-01-09 17:02:49.920 开始执行任务: 360bdae4-2950-4351-af88-9bdc07c69b49, update_system=False
[INFO] 2026-01-09 17:02:53.545 MongoDB 连接成功: slide_svc
[INFO] 2026-01-09 17:02:53.642 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始参数校验...
[INFO] 2026-01-09 17:02:53.642 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始参数校验...
[INFO] 2026-01-09 17:02:53.646 [360bdae4-2950-4351-af88-9bdc07c69b49] 任务状态已更新为 running
[INFO] 2026-01-09 17:02:53.646 [360bdae4-2950-4351-af88-9bdc07c69b49] 任务状态已更新为 running
[INFO] 2026-01-09 17:02:53.653 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始下载文件...
[INFO] 2026-01-09 17:02:53.653 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始下载文件...
[INFO] 2026-01-09 17:02:53.654 [360bdae4-2950-4351-af88-9bdc07c69b49] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 17:02:53.654 [360bdae4-2950-4351-af88-9bdc07c69b49] MinIO 下载参数 - Bucket: kb-paper-original-md, Object: arxiv/2025/2501.11921.md
[INFO] 2026-01-09 17:02:53.654 初始化MinIO客户端: endpoint=10.0.62.206:59003, access_key=admin...
[INFO] 2026-01-09 17:02:53.655 MinIO客户端初始化成功
[INFO] 2026-01-09 17:02:53.938 文件已下载: kb-paper-original-md/arxiv/2025/2501.11921.md -> Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\360bdae4-2950-4351-af88-9bdc07c69b49\2501.11921.md
[INFO] 2026-01-09 17:02:53.939 [360bdae4-2950-4351-af88-9bdc07c69b49] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\360bdae4-2950-4351-af88-9bdc07c69b49\2501.11921.md
[INFO] 2026-01-09 17:02:53.939 [360bdae4-2950-4351-af88-9bdc07c69b49] 文件下载完成: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\data\temp\360bdae4-2950-4351-af88-9bdc07c69b49\2501.11921.md
[INFO] 2026-01-09 17:02:53.943 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始调用生成管道...
[INFO] 2026-01-09 17:02:53.943 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始调用生成管道...
[INFO] 2026-01-09 17:02:53.947 Starting pipeline from stage: plan
[INFO] 2026-01-09 17:02:53.947 Session ID: 151abaa7-58c9-4f57-8f8f-71a0738dc7fc
[INFO] 2026-01-09 17:02:53.947 Base dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper
[INFO] 2026-01-09 17:02:53.948 Config dir: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\slides_academic_long
[INFO] 2026-01-09 17:02:53.951 
[INFO] 2026-01-09 17:02:53.953 Starting from stage: plan
[INFO] 2026-01-09 17:02:59.710 
[INFO] 2026-01-09 17:02:59.712 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:02:59.712 STAGE: PLAN
[INFO] 2026-01-09 17:02:59.713 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:03:05.725 Planning content...
[INFO] 2026-01-09 17:03:07.192 Calling LLM with text only (no images)
[INFO] 2026-01-09 17:03:07.193 Calling gemini-3-flash with max_tokens=16000
[INFO] 2026-01-09 17:03:38.076 LLM returned 6794 characters
[INFO] 2026-01-09 17:03:38.076 ================================================================================
[INFO] 2026-01-09 17:03:38.077 LLM Response for Content Planning:
[INFO] 2026-01-09 17:03:38.077 --------------------------------------------------------------------------------
[INFO] 2026-01-09 17:03:38.077 ```json
{
  "slides": [
    {
      "id": "slide_01",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "content": "作者：Jiazheng Chen, Wanchun Liu* (通讯作者)。本研究针对现代物联网与远程控制系统，提出了一种创新的深度强化学习框架 SUDO-DRL。该研究的核心在于将通信目标的重心从传统的“位级准确度”转向“应用驱动的目标”，例如在远程状态估计中最小化估计误差。通过数学证明最优策略的结构属性（单调性、渐近凸性），并将其融入 DRL 训练过程，本论文成功解决了大规模无线通信系统（如 40 设备 20 信道）中的复杂调度难题，克服了传统 DRL 算法在收敛性、稳定性和样本效率方面的局限性。",
      "tables": [],
      "figures": []
    },
    {
      "id": "slide_02",
      "title": "研究背景与问题定义：面向目标的传输调度",
      "content": "在多设备多信道无线通信系统中，N 个边缘设备共享 M 个有限衰落信道（M < N）。研究的核心问题是寻找最优调度策略 \\( \\pi \\)，以最小化所有设备的长期期望总成本。在远程状态估计场景下，这等同于最小化与信息年龄（AoI）相关的估计状态均方误差（MSE）。\n\n关键挑战包括：\n1. 高维状态空间：必须实时跟踪每个设备的 AoI 和信道状态，复杂度随设备数量呈指数级增长。\n2. 庞大的动作空间：对于 N 设备 M 信道，动作数为 \\( N! / (N-M)! \\)。在 10 设备 5 信道场景下，动作数已达 30,240 个，传统 MDP 求解器完全失效。\n3. 目标转向：从单纯的传输比特转向满足特定应用需求（Remote State Estimation）。",
      "tables": [],
      "figures": []
    },
    {
      "id": "slide_03",
      "title": "现有方法的局限性与研究空白",
      "content": "现有技术在处理大规模目标导向通信时存在显著缺陷：\n1. 传统方法：启发式方法（如 Whittle’s Index）虽快但非最优；动态规划（值迭代/策略迭代）面临“维度灾难”。\n2. 标准 DRL 算法：\n   - 离策（Off-Policy）如 DQN/DDPG：虽样本效率高，但在大型动态系统中训练极不稳定，40 设备场景下无法收敛。\n   - 同策（On-Policy）如 PPO/TRPO：稳定性好但样本效率极低，数据利用率差，易陷入局部最优。\n3. 理论结合缺失：现有研究多采用“暴力优化”，未深入挖掘 AoI 状态最优值函数的数学性质（如单调性、凸性），导致在大规模系统（20-40个传感器）中性能严重下降或不收敛。",
      "tables": [],
      "figures": []
    },
    {
      "id": "slide_04",
      "title": "SUDO-DRL 框架概述：理论与算法的统一",
      "content": "SUDO-DRL (Structure-guided Unified Dual On-off policy DRL) 是一个混合 DRL 框架。其核心思想是结合 PPO 的在线策略训练稳定性与 SAC 的离线策略采样效率，并利用推导出的理论结构属性指导训练。\n\n该框架包含四大创新支柱：\n1. 理论属性推导：证明了 V 函数的单调性与渐近凸性。\n2. 结构评分机制：将理论转化为 CM（单调性）、CC（凸性）、AM（策略单调性）评分。\n3. 统一双损失函数：通过权重 \\( \\beta_1, \\beta_2 \\) 桥接在线与离线更新。\n4. 结构引导回放池：基于评分进行选择性存储和优先级采样，确保模型学习高质量且符合物理规律的数据。",
      "tables": [],
      "figures": []
    },
    {
      "id": "slide_05",
      "title": "理论基础：最优策略的结构属性证明",
      "content": "本研究推导了最优调度策略的四个
[INFO] 2026-01-09 17:03:38.078 ... (truncated, total length: 6794 chars)
[INFO] 2026-01-09 17:03:38.078 ================================================================================
[INFO] 2026-01-09 17:03:38.078 Found JSON in code block
[INFO] 2026-01-09 17:03:38.082   Generated 12 sections:
[INFO] 2026-01-09 17:03:38.082     [1] Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach (opening)
[INFO] 2026-01-09 17:03:38.082     [2] 研究背景与问题定义：面向目标的传输调度 (content)
[INFO] 2026-01-09 17:03:38.082     [3] 现有方法的局限性与研究空白 (content)
[INFO] 2026-01-09 17:03:38.083     [4] SUDO-DRL 框架概述：理论与算法的统一 (content)
[INFO] 2026-01-09 17:03:38.083     [5] 理论基础：最优策略的结构属性证明 (content)
[INFO] 2026-01-09 17:03:38.083     [6] 结构属性评估框架与量化指标 (content)
[INFO] 2026-01-09 17:03:38.083     [7] 统一双损失函数 (Unified Dual Loss Function) (content)
[INFO] 2026-01-09 17:03:38.084     [8] 回放池管理与结构引导预训练 (content)
[INFO] 2026-01-09 17:03:38.084     [9] 实验设置：远程状态估计仿真 (content)
[INFO] 2026-01-09 17:03:38.084     [10] 性能对比：SUDO-DRL 的卓越表现 (content)
[INFO] 2026-01-09 17:03:38.085     [11] 消融研究与收敛效率分析 (content)
[INFO] 2026-01-09 17:03:38.085     [12] 结论与贡献总结 (ending)
[INFO] 2026-01-09 17:03:38.104   Saved: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\slides_academic_long\checkpoint_plan.json
[INFO] 2026-01-09 17:03:38.107 
[INFO] 2026-01-09 17:03:38.107 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:03:38.107 STAGE: GENERATE
[INFO] 2026-01-09 17:03:38.107 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:03:38.120 Generating images...
[INFO] 2026-01-09 17:03:40.160 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:03:40.161   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:03:40.162   Prompt length: 6229 chars
[INFO] 2026-01-09 17:03:54.607 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:03:55.446 Image generation successful (Doubao, URL, 1030514 bytes)
[INFO] 2026-01-09 17:03:55.451   [1/12] Saved: slide_01.png
[INFO] 2026-01-09 17:03:55.451 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:03:55.452   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:03:55.452   Prompt length: 6377 chars
[INFO] 2026-01-09 17:04:14.217 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:04:15.540 Image generation successful (Doubao, URL, 1078835 bytes)
[INFO] 2026-01-09 17:04:15.561   [2/12] Saved: slide_02.png
[INFO] 2026-01-09 17:04:15.565   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:04:15.568 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:04:15.570   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:04:15.572   Prompt length: 6515 chars
[INFO] 2026-01-09 17:04:34.408 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:04:35.188 Image generation successful (Doubao, URL, 989454 bytes)
[INFO] 2026-01-09 17:04:35.189   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:04:35.189 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:04:35.191   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:04:35.191   [3/12] Saved: slide_03.png
[INFO] 2026-01-09 17:04:35.191   Prompt length: 6528 chars
[INFO] 2026-01-09 17:04:59.366 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:04:59.927 Image generation successful (Doubao, URL, 859802 bytes)
[INFO] 2026-01-09 17:04:59.928   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:04:59.929 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:04:59.930   [4/12] Saved: slide_04.png
[INFO] 2026-01-09 17:04:59.930   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:04:59.930   Prompt length: 6570 chars
[INFO] 2026-01-09 17:05:16.850 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:05:17.442 Image generation successful (Doubao, URL, 989954 bytes)
[INFO] 2026-01-09 17:05:17.444   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:05:17.444 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:05:17.445   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:05:17.445   Prompt length: 6740 chars
[INFO] 2026-01-09 17:05:17.449   [5/12] Saved: slide_05.png
[INFO] 2026-01-09 17:05:45.006 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:05:45.594 Image generation successful (Doubao, URL, 927290 bytes)
[INFO] 2026-01-09 17:05:45.597   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:05:45.598 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:05:45.598   [6/12] Saved: slide_06.png
[INFO] 2026-01-09 17:05:45.599   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:05:45.599   Prompt length: 6690 chars
[INFO] 2026-01-09 17:06:01.396 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:06:02.396 Image generation successful (Doubao, URL, 847245 bytes)
[INFO] 2026-01-09 17:06:02.399   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:06:02.401   [7/12] Saved: slide_07.png
[INFO] 2026-01-09 17:06:02.402 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:06:02.403   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:06:02.404   Prompt length: 6506 chars
[INFO] 2026-01-09 17:06:18.658 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:06:19.400 Image generation successful (Doubao, URL, 896752 bytes)
[INFO] 2026-01-09 17:06:19.403   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:06:19.404 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:06:19.404   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:06:19.404   [8/12] Saved: slide_08.png
[INFO] 2026-01-09 17:06:19.404   Prompt length: 6831 chars
[INFO] 2026-01-09 17:06:40.555 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:06:41.438 Image generation successful (Doubao, URL, 1054281 bytes)
[INFO] 2026-01-09 17:06:41.440   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:06:41.441 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:06:41.441   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:06:41.441   Prompt length: 6916 chars
[INFO] 2026-01-09 17:06:41.446   [9/12] Saved: slide_09.png
[INFO] 2026-01-09 17:07:03.245 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:07:03.865 Image generation successful (Doubao, URL, 986780 bytes)
[INFO] 2026-01-09 17:07:03.867   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:07:03.868 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:07:03.868   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:07:03.868   [10/12] Saved: slide_10.png
[INFO] 2026-01-09 17:07:03.870   Prompt length: 6455 chars
[INFO] 2026-01-09 17:07:20.466 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:07:21.245 Image generation successful (Doubao, URL, 1017176 bytes)
[INFO] 2026-01-09 17:07:21.248   Including 1 reference image descriptions in prompt
[INFO] 2026-01-09 17:07:21.249 Calling Doubao image generation (attempt 1/3)...
[INFO] 2026-01-09 17:07:21.250   Model: doubao-seedream-4-5-251128, Size: 2K
[INFO] 2026-01-09 17:07:21.250   [11/12] Saved: slide_11.png
[INFO] 2026-01-09 17:07:21.250   Prompt length: 6309 chars
[INFO] 2026-01-09 17:07:36.579 Downloading image from URL: https://ark-content-generation-v2-cn-beijing.tos-cn-beijing.volces.com/doubao-se...
[INFO] 2026-01-09 17:07:37.269 Image generation successful (Doubao, URL, 1021670 bytes)
[INFO] 2026-01-09 17:07:37.272   [12/12] Saved: slide_12.png
[INFO] 2026-01-09 17:07:37.273   Generated 12 images
[INFO] 2026-01-09 17:07:37.874   Saved: slides.pdf
[INFO] 2026-01-09 17:07:37.875 
[INFO] 2026-01-09 17:07:37.875 Output: Z:\PythonWorkSpace\sophyverse-platform-backend\src\slide-svc\outputs\2501.11921\paper\fast\slides_academic_long\20260109_170338
[INFO] 2026-01-09 17:07:37.880 
[INFO] 2026-01-09 17:07:37.880 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:07:37.881 SUMMARY
[INFO] 2026-01-09 17:07:37.881 ────────────────────────────────────────────────────────────
[INFO] 2026-01-09 17:07:37.881   [○] rag: pending
[INFO] 2026-01-09 17:07:37.882   [○] summary: pending
[INFO] 2026-01-09 17:07:37.882   [✓] plan: completed
[INFO] 2026-01-09 17:07:37.882   [✓] generate: completed
[INFO] 2026-01-09 17:07:37.885 [360bdae4-2950-4351-af88-9bdc07c69b49] 生成完成，输出文件: 13 个
[INFO] 2026-01-09 17:07:37.885 [360bdae4-2950-4351-af88-9bdc07c69b49] 生成完成，输出文件: 13 个
[INFO] 2026-01-09 17:07:37.916 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始上传文件...
[INFO] 2026-01-09 17:07:37.916 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始上传文件...
[INFO] 2026-01-09 17:07:37.992 已创建 MinIO bucket: kb-slide-user
[INFO] 2026-01-09 17:07:38.659 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/slides.pdf
[INFO] 2026-01-09 17:07:38.952 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_01.png
[INFO] 2026-01-09 17:07:39.265 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_02.png
[INFO] 2026-01-09 17:07:39.556 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_03.png
[INFO] 2026-01-09 17:07:39.813 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_04.png
[INFO] 2026-01-09 17:07:40.093 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_05.png
[INFO] 2026-01-09 17:07:40.344 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_06.png
[INFO] 2026-01-09 17:07:40.573 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_07.png
[INFO] 2026-01-09 17:07:40.823 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_08.png
[INFO] 2026-01-09 17:07:41.094 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_09.png
[INFO] 2026-01-09 17:07:41.342 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_10.png
[INFO] 2026-01-09 17:07:41.596 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_11.png
[INFO] 2026-01-09 17:07:41.849 文件已上传: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_12.png
[INFO] 2026-01-09 17:07:41.850 [360bdae4-2950-4351-af88-9bdc07c69b49] 文件上传完成: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/slides.pdf
[INFO] 2026-01-09 17:07:41.850 [360bdae4-2950-4351-af88-9bdc07c69b49] 文件上传完成: kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/slides.pdf
[INFO] 2026-01-09 17:07:41.857 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始更新用户数据...
[INFO] 2026-01-09 17:07:41.857 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始更新用户数据...
[INFO] 2026-01-09 17:07:41.873 只更新当前任务: 360bdae4-2950-4351-af88-9bdc07c69b49, update_system=False
[INFO] 2026-01-09 17:07:41.873 只更新当前任务: 360bdae4-2950-4351-af88-9bdc07c69b49, update_system=False
[INFO] 2026-01-09 17:07:41.874 [360bdae4-2950-4351-af88-9bdc07c69b49] 用户数据更新完成
[INFO] 2026-01-09 17:07:41.874 [360bdae4-2950-4351-af88-9bdc07c69b49] 用户数据更新完成
[INFO] 2026-01-09 17:07:41.881 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始更新系统数据...
[INFO] 2026-01-09 17:07:41.881 [360bdae4-2950-4351-af88-9bdc07c69b49] 开始更新系统数据...
[INFO] 2026-01-09 17:07:41.884 [360bdae4-2950-4351-af88-9bdc07c69b49] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 17:07:41.884 [360bdae4-2950-4351-af88-9bdc07c69b49] 跳过系统数据更新, paper_type=user, update_system=False
[INFO] 2026-01-09 17:07:41.891 任务执行完成: 360bdae4-2950-4351-af88-9bdc07c69b49, status=success
[INFO] 2026-01-09 17:07:41.891 任务执行完成: 360bdae4-2950-4351-af88-9bdc07c69b49, status=success
[INFO] 2026-01-09 17:07:41.893 任务成功: 360bdae4-2950-4351-af88-9bdc07c69b49
[INFO] 2026-01-09 17:07:41.893 任务成功: 360bdae4-2950-4351-af88-9bdc07c69b49
[INFO] 2026-01-09 17:07:43.933 运行中任务数减少: 0
[INFO] 2026-01-09 17:07:43.942 已清理临时文件: 360bdae4-2950-4351-af88-9bdc07c69b49
[INFO] 2026-01-09 17:07:43.942 已清理临时文件: 360bdae4-2950-4351-af88-9bdc07c69b49
[INFO] 2026-01-09 17:07:43.957 Task celery_app.tasks.generate_slides_task[360bdae4-2950-4351-af88-9bdc07c69b49] succeeded in 296.14099999982864s: {'result_id': '360bdae4-2950-4351-af88-9bdc07c69b49', 'status': 'success', 'file_path': 'kb-slide-user/0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/slides.pdf', 'images': ['0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_01.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_02.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_03.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_04.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_05.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_06.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/slide_07.png', '0d55e6afb59cb5012a0dcff67a6ee742/2501.11921/360bdae4-2950-4351-af88-9bdc07c69b49/images/...', ...]}
[WARNING] 2026-01-09 17:17:54.202 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 17:17:56.240 Connected to redis://:**@localhost:6379/0
[WARNING] 2026-01-09 17:17:56.245 X:\Anaconda\envs\slide-svc\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[INFO] 2026-01-09 17:17:58.290 mingle: searching for neighbors
[INFO] 2026-01-09 17:18:05.477 mingle: all alone
[INFO] 2026-01-09 17:18:15.726 celery@DESKTOP-4FIVBBU ready.
